{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import constants_aspects_analysis as constants\n",
    "import preprocess_helper as helper\n",
    "import re\n",
    "from xml import etree\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize,sent_tokenize, pos_tag\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from data_logger import DataLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_listxml(acorpus, aname_tag):\n",
    "    return acorpus.findall(aname_tag)\n",
    "\n",
    "def string_nested_xml(axml):\n",
    "    return ' '.join([the_aiter for the_aiter in axml.itertext()])\n",
    "\n",
    "def get_firstchild(axml):\n",
    "    try:\n",
    "        if len(axml.getchildren()) > 0:\n",
    "            return axml.getchildren()[0].tag\n",
    "        else:\n",
    "            raise (Exception('ListIndex', 'aXmlElement input has no children.'))\n",
    "    except Exception as e:\n",
    "        print (str(e))\n",
    "\n",
    "def xml_unique_valid(axml, alist_tag_allowed):\n",
    "    return (len(axml.getchildren()) == 0) or (get_firstchild(axml) in alist_tag_allowed)\n",
    "\n",
    "def get_listsentence_unique(alist_xml, alist_tag_allowed):\n",
    "    the_listsentence = []\n",
    "    for the_axml in alist_xml:\n",
    "        if xml_unique_valid(the_axml, alist_tag_allowed):\n",
    "            the_listsentence.append(string_nested_xml(the_axml))\n",
    "\n",
    "    return the_listsentence\n",
    "\n",
    "def xml_name_valid(axml, atag_name):\n",
    "    return axml.tag == atag_name\n",
    "\n",
    "def get_listxml_child(alist_xml, atag_name):\n",
    "    the_listreturn = []\n",
    "    for the_axml in alist_xml:\n",
    "        for the_achild in the_axml:\n",
    "            if xml_name_valid(the_achild, atag_name):\n",
    "                the_listreturn.append(the_achild)\n",
    "\n",
    "    return the_listreturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'CORPUS_XML_FILE_LOCATION': './data/User Review Structure Analysis '\n                             '(URSA)/Classified_Corpus.xml',\n 'FILE_LOG_AMBIENCE_NOT_PASS': 'ambience_not_pass.txt',\n 'FILE_LOG_AMBIENCE_NOT_PASS_LOCATION': './data/User Review Structure Analysis '\n                                        '(URSA)/ambience_not_pass.txt',\n 'FILE_LOG_FOOD_NOT_PASS': 'food_not_pass.txt',\n 'FILE_LOG_FOOD_NOT_PASS_LOCATION': './data/User Review Structure Analysis '\n                                    '(URSA)/food_not_pass.txt',\n 'FILE_LOG_STAFF_NOT_PASS': 'staff_not_pass.txt',\n 'FILE_LOG_STAFF_NOT_PASS_LOCATION': './data/User Review Structure Analysis '\n                                     '(URSA)/staff_not_pass.txt',\n 'FILE_SEED_WORD': 'seed_words.txt',\n 'FILE_SEED_WORD_LOCATION': './data/User Review Structure Analysis '\n                            '(URSA)/seed_words.txt',\n 'FOLDER_DATASET': './data/User Review Structure Analysis (URSA)/',\n 'LABEL_REVIEW_AMBIENCE': 2,\n 'LABEL_REVIEW_FOOD': 0,\n 'LABEL_REVIEW_STAFF': 1,\n 'LENGTH_AMBIENCE_ALLOWED': -1,\n 'LENGTH_FOOD_ALLOWED': -1,\n 'LENGTH_STAFF_ALLOWED': -1,\n 'LIST_LABEL': [0, 1, 2],\n 'MIN_FREQ_ALLOWED': -1,\n 'PRINT_STATUS': True,\n 'SAMPLE_INDEX_FROM': 0,\n 'SAMPLE_INDEX_TO': 5,\n 'TAG_NAME_AMBIENCE': 'Ambience',\n 'TAG_NAME_FOOD': 'Food',\n 'TAG_NAME_POLARITY_ALLOWED': ['Positive', 'Negative', 'Neutral'],\n 'TAG_NAME_STAFF': 'Staff',\n 'TAG_XML_REVIEW': './/Review',\n 'TRAIN_FILENAME_SAVE': 'train.txt.npy',\n 'TRAIN_FILE_LOCATION': './data/User Review Structure Analysis '\n                        '(URSA)/train.txt.npy',\n 'VOCAB_FILENAME_SAVE': 'vocab.pkl',\n 'VOCAB_FILE_LOCATION': './data/User Review Structure Analysis '\n                        '(URSA)/vocab.pkl',\n 'XML_FILENAME': 'Classified_Corpus.xml'}\n"
     ]
    }
   ],
   "source": [
    "data_logger_util = DataLogger()\n",
    "helper.variable_information(constants.const, constants.const.PRINT_STATUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tree = ET.parse(constants.const.CORPUS_XML_FILE_LOCATION)\n",
    "corpus = corpus_tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdocument = find_listxml(corpus, constants.const.TAG_XML_REVIEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "listxml_child_food = get_listxml_child(listdocument, constants.const.TAG_NAME_FOOD)\n",
    "listxml_child_staff = get_listxml_child(listdocument, constants.const.TAG_NAME_STAFF)\n",
    "listxml_child_ambience = get_listxml_child(listdocument, constants.const.TAG_NAME_AMBIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length  listxml_child_food \t:  96235\nLength  listxml_child_staff \t:  32892\nLength  listxml_child_ambience \t:  16803\n"
     ]
    }
   ],
   "source": [
    "helper.print_length_variables([listxml_child_food, listxml_child_staff, listxml_child_ambience], \\\n",
    "                               ['listxml_child_food', 'listxml_child_staff', 'listxml_child_ambience'], \\\n",
    "                               constants.const.PRINT_STATUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FOOD ##### STAFF ##### AMBIENCE\n",
    "listxml_unique_food = get_listsentence_unique(listxml_child_food, \\\n",
    "                                                constants.const.TAG_NAME_POLARITY_ALLOWED)\n",
    "listxml_unique_staff = get_listsentence_unique(listxml_child_staff, \\\n",
    "                                              constants.const.TAG_NAME_POLARITY_ALLOWED)\n",
    "listxml_unique_ambience = get_listsentence_unique(listxml_child_ambience, \\\n",
    "                                              constants.const.TAG_NAME_POLARITY_ALLOWED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length  listxml_unique_food \t:  62348\nLength  listxml_unique_staff \t:  23730\nLength  listxml_unique_ambience \t:  13385\n"
     ]
    }
   ],
   "source": [
    "helper.print_length_variables([listxml_unique_food, listxml_unique_staff, listxml_unique_ambience], \\\n",
    "                              ['listxml_unique_food', 'listxml_unique_staff', 'listxml_unique_ambience'], \\\n",
    "                              constants.const.PRINT_STATUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "listprocessed_food = helper.process_listtext(listxml_unique_food, constants.const.LENGTH_FOOD_ALLOWED, \\\n",
    "                                             constants.const.FILE_LOG_FOOD_NOT_PASS_LOCATION)\n",
    "listprocessed_staff = helper.process_listtext(listxml_unique_staff, constants.const.LENGTH_STAFF_ALLOWED,\\\n",
    "                                              constants.const.FILE_LOG_STAFF_NOT_PASS_LOCATION)\n",
    "listprocessed_ambience = helper.process_listtext(listxml_unique_ambience, constants.const.LENGTH_AMBIENCE_ALLOWED, \\\n",
    "                                                 constants.const.FILE_LOG_AMBIENCE_NOT_PASS_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length  listprocessed_food \t:  62348\nLength  listprocessed_staff \t:  23730\nLength  listprocessed_ambience \t:  13385\n"
     ]
    }
   ],
   "source": [
    "helper.print_length_variables([listprocessed_food, listprocessed_staff, listprocessed_ambience], \\\n",
    "                              ['listprocessed_food', 'listprocessed_staff', 'listprocessed_ambience'], \\\n",
    "                              constants.const.PRINT_STATUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "listlabeled_food = helper.label_listdata(listprocessed_food, constants.const.LABEL_REVIEW_FOOD)\n",
    "listlabeled_staff = helper.label_listdata(listprocessed_staff, constants.const.LABEL_REVIEW_STAFF)\n",
    "listlabeled_ambience = helper.label_listdata(listprocessed_ambience, constants.const.LABEL_REVIEW_AMBIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length  listlabeled_food \t:  62348\nLength  listlabeled_staff \t:  23730\nLength  listlabeled_ambience \t:  13385\n###  listxml_unique_ambience ###\n#  In Short In nice weather , the front doors are flung open to the air ; cold nights find patrons tucked into rear booths . \n#  Great for groups , great for a date , great for early brunch or a nightcap . \n#  Upon using their bathroom ( btw , don't ) I found that the other side of the restaurant was air condtioned and there were a few empty tables . \n#  It became impossible to stand and have a drink or any type of conversation . \n#  its a fun environment and they play good music as well . \n###  listprocessed_ambience ###\n# ['short', 'nice', 'weather', 'front', 'door', 'flung', 'open', 'air', 'cold', 'night', 'find', 'patron', 'tuck', 'rear', 'booth']\n# ['great', 'group', 'great', 'date', 'great', 'earli', 'brunch', 'nightcap']\n# ['upon', 'use', 'bathroom', 'btw', 'found', 'side', 'restaur', 'air', 'condtion', 'empti', 'tabl']\n# ['becam', 'imposs', 'stand', 'drink', 'type', 'convers']\n# ['fun', 'environ', 'play', 'good', 'music', 'well']\n###  listlabeled_ambience ###\n# (['short', 'nice', 'weather', 'front', 'door', 'flung', 'open', 'air', 'cold', 'night', 'find', 'patron', 'tuck', 'rear', 'booth'], 2)\n# (['great', 'group', 'great', 'date', 'great', 'earli', 'brunch', 'nightcap'], 2)\n# (['upon', 'use', 'bathroom', 'btw', 'found', 'side', 'restaur', 'air', 'condtion', 'empti', 'tabl'], 2)\n# (['becam', 'imposs', 'stand', 'drink', 'type', 'convers'], 2)\n# (['fun', 'environ', 'play', 'good', 'music', 'well'], 2)\n"
     ]
    }
   ],
   "source": [
    "helper.print_length_variables([listlabeled_food, listlabeled_staff, listlabeled_ambience], \\\n",
    "                              ['listlabeled_food', 'listlabeled_staff', 'listlabeled_ambience'], \\\n",
    "                              constants.const.PRINT_STATUS)\n",
    "\n",
    "helper.print_listsample([listxml_unique_ambience, listprocessed_ambience, listlabeled_ambience], \\\n",
    "                        ['listxml_unique_ambience', 'listprocessed_ambience', 'listlabeled_ambience'], \\\n",
    "                        constants.const.SAMPLE_INDEX_FROM, constants.const.SAMPLE_INDEX_TO, constants.const.PRINT_STATUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vocab_dict = helper.create_vocab_listsentence(listprocessed_food + listprocessed_staff + listprocessed_ambience, constants.const.MIN_FREQ_ALLOWED)\n",
    "\n",
    "list_onehot = helper.create_listonehot(listlabeled_food + listlabeled_staff + listlabeled_ambience, \\\n",
    "                                       vocab, vocab_dict)\n",
    "\n",
    "# Save Into File\n",
    "np.save (constants.const.TRAIN_FILE_LOCATION, list_onehot)\n",
    "data_logger_util.pickle(constants.const.VOCAB_FILE_LOCATION, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable create corpus and compute coherent\n",
    "folder_corpus=\"corpus\"\n",
    "filename_corpus=\"ursa_a\"\n",
    "filename_corpus0=\"ursa.0\"\n",
    "filename_corpus1=\"ursa.1\"\n",
    "filename_corpus2=\"ursa.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create corpus\n",
    "file_corpus = open('corpus/{0}'.format(filename_corpus), 'w+')\n",
    "file_corpus0 = open('corpus/{0}'.format(filename_corpus0), 'w+')\n",
    "file_corpus1 = open('corpus/{0}'.format(filename_corpus1), 'w+')\n",
    "file_corpus2 = open('corpus/{0}'.format(filename_corpus2), 'w+')\n",
    "\n",
    "for sentence in listprocessed_food:\n",
    "    file_corpus0.write('{0}\\n'.format(\" \".join([w for w in sentence])))\n",
    "    file_corpus.write('{0}\\n'.format(\" \".join([w for w in sentence])))\n",
    "    \n",
    "for sentence in listprocessed_staff:\n",
    "    file_corpus1.write('{0}\\n'.format(\" \".join([w for w in sentence])))\n",
    "    file_corpus.write('{0}\\n'.format(\" \".join([w for w in sentence])))\n",
    "    \n",
    "for sentence in listprocessed_ambience:  \n",
    "    file_corpus2.write('{0}\\n'.format(\" \".join([w for w in sentence])))\n",
    "    file_corpus.write('{0}\\n'.format(\" \".join([w for w in sentence])))\n",
    "\n",
    "file_corpus.close()\n",
    "file_corpus0.close()\n",
    "file_corpus1.close()\n",
    "file_corpus2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "db9eba5db4e480122b2be0087a0905dc2ea1f06dac56426d2ab1de8f46c556b4"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}