{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install https://download.pytorch.org/whl/cu75/torch-0.1.12.post1-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(data, min_length):\n",
    "    return np.bincount(data, minlength=min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perp(model):\n",
    "    cost=[]\n",
    "    model.eval()                        # switch to testing mode\n",
    "    input_ = tensor_te\n",
    "    recon, loss = model(input_, compute_loss=True, avg_loss=False)\n",
    "    loss = loss.data\n",
    "    counts = tensor_te.sum(1)\n",
    "    avg = (loss / counts).mean()\n",
    "    print('The approximated perplexity is: ', math.exp(avg))\n",
    "\n",
    "def visualize():\n",
    "    global recon\n",
    "    input_ = tensor_te[:10]\n",
    "    register_vis_hooks(model)\n",
    "    recon = model(input_, compute_loss=False)\n",
    "    remove_vis_hooks()\n",
    "    save_visualization('pytorch_model', 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tr = 'data/20news_clean/train.txt.npy'\n",
    "data_tr = np.load(dataset_tr, encoding=\"latin1\")\n",
    "dataset_te = 'data/20news_clean/test.txt.npy'\n",
    "data_te = np.load(dataset_te, encoding=\"latin1\")\n",
    "vocab = 'data/20news_clean/vocab.pkl'\n",
    "vocab_file = open(vocab,'rb')\n",
    "vocab = pickle.load(vocab_file)\n",
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data to one-hot representation\n",
      "Data Loaded\n",
      "Dim Training Data (11258, 1995)\n",
      "Dim Test Data (7487, 1995)\n"
     ]
    }
   ],
   "source": [
    "#--------------convert to one-hot representation------------------\n",
    "print ('Converting data to one-hot representation')\n",
    "data_tr = np.array([to_onehot(doc.astype('int'),vocab_size) for doc in data_tr if np.sum(doc)!=0])\n",
    "data_te = np.array([to_onehot(doc.astype('int'),vocab_size) for doc in data_te if np.sum(doc)!=0])\n",
    "#--------------print the data dimentions--------------------------\n",
    "print ('Data Loaded')\n",
    "print ('Dim Training Data', data_tr.shape)\n",
    "print ('Dim Test Data', data_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------make tensor datasets-------------------------------\n",
    "tensor_tr = torch.from_numpy(data_tr).float()\n",
    "tensor_te = torch.from_numpy(data_te).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProdLDA(nn.Module):\n",
    "    def __init__(self, net_arch):\n",
    "        super(ProdLDA, self).__init__()\n",
    "        ac = net_arch\n",
    "        self.net_arch = net_arch\n",
    "        # encoder\n",
    "        self.en1_fc     = nn.Linear(ac.num_input, ac.en1_units)             # 1995 -> 100\n",
    "        self.en2_fc     = nn.Linear(ac.en1_units, ac.en2_units)             # 100  -> 100\n",
    "        self.en2_drop   = nn.Dropout(ac.drop_rate)\n",
    "        self.mean_fc    = nn.Linear(ac.en2_units, ac.num_topic)             # 100  -> 50\n",
    "        self.mean_bn    = nn.BatchNorm1d(ac.num_topic)                      # bn for mean\n",
    "        self.logvar_fc  = nn.Linear(ac.en2_units, ac.num_topic)             # 100  -> 50\n",
    "        self.logvar_bn  = nn.BatchNorm1d(ac.num_topic)                      # bn for logvar\n",
    "        self.en = nn.Sequential(OrderedDict([\n",
    "            ('linear1', nn.Linear(ac.num_input, ac.en1_units)),\n",
    "            ('act1', nn.Softplus()),\n",
    "            ('linear2', nn.Linear(ac.en1_units, ac.en2_units)),\n",
    "            ('act2', nn.Softplus()),\n",
    "            ('dropout', nn.Dropout(ac.drop_rate))\n",
    "        ]))\n",
    "        self.mean = nn.Sequential(OrderedDict([\n",
    "            ('linear', nn.Linear(ac.en2_units, ac.num_topic)),\n",
    "            ('batchnorm', nn.BatchNorm1d(ac.num_topic))\n",
    "        ]))\n",
    "        self.logvar = nn.Sequential(OrderedDict([\n",
    "            ('linear', nn.Linear(ac.en2_units, ac.num_topic)),\n",
    "            ('batchnorm', nn.BatchNorm1d(ac.num_topic))\n",
    "        ]))\n",
    "        \n",
    "        self.de = nn.Sequential(OrderedDict([\n",
    "            ('act1', nn.Softmax(dim=-1)),\n",
    "            ('dropout', nn.Dropout(ac.drop_rate)),\n",
    "            ('linear', nn.Linear(ac.num_topic, ac.num_input)),\n",
    "            ('batchnorm', nn.BatchNorm1d(ac.num_input)),\n",
    "            ('act2', nn.Softmax(dim=-1))\n",
    "        ]))\n",
    "        # prior mean and variance as constant buffers\n",
    "        self.prior_mean   = torch.Tensor(1, ac.num_topic).fill_(0)\n",
    "        self.prior_var    = torch.Tensor(1, ac.num_topic).fill_(ac.variance)\n",
    "        self.prior_mean = nn.Parameter(self.prior_mean, requires_grad=False)\n",
    "        self.prior_var = nn.Parameter(self.prior_var, requires_grad=False)\n",
    "        self.prior_logvar = nn.Parameter(self.prior_var.log(), requires_grad=False)\n",
    "        # initialize decoder weight\n",
    "        if ac.init_mult != 0:\n",
    "            #std = 1. / math.sqrt( ac.init_mult * (ac.num_topic + ac.num_input))\n",
    "            self.de.linear.weight.data.uniform_(0, ac.init_mult)\n",
    "        # remove BN's scale parameters\n",
    "        for component in [self.mean, self.logvar, self.de]:\n",
    "            component.batchnorm.weight.requires_grad = False\n",
    "            component.batchnorm.weight.fill_(1.0)\n",
    "\n",
    "    def encode(self, input_):\n",
    "        encoded = self.en(input_)\n",
    "        posterior_mean = self.mean(encoded)\n",
    "        posterior_logvar = self.logvar(encoded)\n",
    "        return encoded, posterior_mean, posterior_logvar\n",
    "    \n",
    "    def decode(self, input_, posterior_mean, posterior_var):\n",
    "        # take sample\n",
    "        eps = input_.data.new().resize_as_(posterior_mean.data).normal_() # noise \n",
    "        z = posterior_mean + posterior_var.sqrt() * eps                   # reparameterization\n",
    "        # do reconstruction\n",
    "        recon = self.de(z)          # reconstructed distribution over vocabulary\n",
    "        return recon\n",
    "    \n",
    "    def forward(self, input_, compute_loss=False, avg_loss=True):\n",
    "        # compute posterior\n",
    "        en2, posterior_mean, posterior_logvar = self.encode(input_) \n",
    "        posterior_var    = posterior_logvar.exp()\n",
    "        \n",
    "        recon = self.decode(input_, posterior_mean, posterior_var)\n",
    "        if compute_loss:\n",
    "            return recon, self.loss(input_, recon, posterior_mean, posterior_logvar, posterior_var, avg_loss)\n",
    "        else:\n",
    "            return recon\n",
    "\n",
    "    def loss(self, input_, recon, posterior_mean, posterior_logvar, posterior_var, avg=True):\n",
    "        # NL\n",
    "        NL  = -(input_ * (recon + 1e-10).log()).sum(1)\n",
    "        # KLD, see Section 3.3 of Akash Srivastava and Charles Sutton, 2017, \n",
    "        # https://arxiv.org/pdf/1703.01488.pdf\n",
    "        prior_mean   = self.prior_mean.expand_as(posterior_mean)\n",
    "        prior_var    = self.prior_var.expand_as(posterior_mean)\n",
    "        prior_logvar = self.prior_logvar.expand_as(posterior_mean)\n",
    "        var_division    = posterior_var  / prior_var\n",
    "        diff            = posterior_mean - prior_mean\n",
    "        diff_term       = diff * diff / prior_var\n",
    "        logvar_division = prior_logvar - posterior_logvar\n",
    "        # put KLD together\n",
    "        KLD = 0.5 * ( (var_division + diff_term + logvar_division).sum(1) - self.net_arch.num_topic )\n",
    "        # loss\n",
    "        loss = (NL + KLD)\n",
    "        # in traiming mode, return averaged loss. In testing mode, return individual loss\n",
    "        if avg:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    en1_units=100\n",
    "    en2_units=100\n",
    "    num_topic=50\n",
    "    num_input=1995\n",
    "    variance=0.995\n",
    "    init_mult=1.0\n",
    "    learning_rate=0.002\n",
    "    batch_size=200\n",
    "    momentum=0.99\n",
    "    num_epoch=100\n",
    "    nogpu=True\n",
    "    drop_rate=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch = args # en1_units, en2_units, num_topic, num_input\n",
    "net_arch.num_input = data_tr.shape[1]\n",
    "model = ProdLDA(net_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size = 10\n",
    "# N = 3\n",
    "# K = 2\n",
    "# input_.data.new().resize_as_(posterior_mean.data).normal_()\n",
    "# input_ = torch.randint(0, 10, (3, 10))\n",
    "# posterior_mean = torch.randint(0, 10, (3, 2))\n",
    "# posterior_mean\n",
    "# input_\n",
    "# input_.data.new().resize_as_(posterior_mean.data).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), args.learning_rate, betas=(args.momentum, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=744.3255818684896\n",
      "Epoch 5, loss=677.8445091916803\n",
      "Epoch 10, loss=661.1274039285224\n",
      "Epoch 15, loss=650.3963317871094\n",
      "Epoch 20, loss=648.0864969889323\n",
      "Epoch 25, loss=644.8758148728756\n",
      "Epoch 30, loss=635.3875571803043\n",
      "Epoch 35, loss=630.1503595720258\n",
      "Epoch 40, loss=626.6581356650904\n",
      "Epoch 45, loss=623.0975084806744\n",
      "Epoch 50, loss=620.9949945817914\n",
      "Epoch 55, loss=617.2237002724096\n",
      "Epoch 60, loss=616.3330522503769\n",
      "Epoch 65, loss=615.0380334686814\n",
      "Epoch 70, loss=613.6359167266311\n",
      "Epoch 75, loss=613.9560643246299\n",
      "Epoch 80, loss=611.7194620768229\n",
      "Epoch 85, loss=611.8647321734512\n",
      "Epoch 90, loss=612.314353005928\n",
      "Epoch 95, loss=609.612364651864\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.num_epoch):\n",
    "    all_indices = torch.randperm(tensor_tr.size(0)).split(args.batch_size)\n",
    "    loss_epoch = 0.0\n",
    "    model.train()                    # switch to training mode\n",
    "    for batch_indices in all_indices:\n",
    "        input_ = tensor_tr[batch_indices]\n",
    "        recon, loss = model(input_, compute_loss=True)\n",
    "        # optimize\n",
    "        optimizer.zero_grad()        # clear previous gradients\n",
    "        loss.backward()              # backprop\n",
    "        optimizer.step()             # update parameters\n",
    "        # report\n",
    "        loss_epoch += loss.item()    # add loss to loss_epoch\n",
    "    if epoch % 5 == 0:\n",
    "        print('Epoch {}, loss={}'.format(epoch, loss_epoch / len(all_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perp(model):\n",
    "    cost=[]\n",
    "    model.eval()                        # switch to testing mode\n",
    "    input_ = tensor_te\n",
    "    recon, loss = model(input_, compute_loss=True, avg_loss=False)\n",
    "    loss = loss.data\n",
    "    counts = tensor_te.sum(1)\n",
    "    avg = (loss / counts).mean()\n",
    "    print('The approximated perplexity is: ', math.exp(avg))\n",
    "\n",
    "def visualize():\n",
    "    global recon\n",
    "    input_ = tensor_te[:10]\n",
    "    register_vis_hooks(model)\n",
    "    recon = model(input_, compute_loss=False)\n",
    "    remove_vis_hooks()\n",
    "    save_visualization('pytorch_model', 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(beta, feature_names, n_top_words=10):\n",
    "    print ('---------------Printing the Topics------------------')\n",
    "    for i in range(len(beta)):\n",
    "        line = \" \".join([feature_names[j] \n",
    "                         for j in beta[i].argsort()[:-n_top_words - 1:-1]])\n",
    "        print('{}'.format(line))\n",
    "    print ('---------------End of Topics------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Printing the Topics------------------\n",
      "pittsburgh louis jose pp minnesota boston philadelphia calgary la montreal\n",
      "doctrine bible christian scripture explanation christianity biblical hang revelation tradition\n",
      "encrypt pgp rsa xlib implementation xt distribution cipher cryptography toolkit\n",
      "crypto outlet escrow ground motor encryption trip voltage panel hide\n",
      "baseball hitter fan ball pitch sport braves stanley roger craig\n",
      "armenian turkish genocide turks greece militia jews organize constitution army\n",
      "cryptography security social responsibility privacy electronic anonymous rsa threat email\n",
      "shipping launch sale ice remote speaker iii cd contract sport\n",
      "hello appreciate hus fax email advance thanks anybody tel institute\n",
      "shipping speaker oo honda rf sale mw mount ac bike\n",
      "entry remark contest oname null output winner int rule printf\n",
      "gateway swap meg ram window isa windows microsoft bus button\n",
      "lebanon civilian village israel armenia israeli troops soldier lebanese armenians\n",
      "morality moral conclusion objective christianity definition murder existence absolute natural\n",
      "apartment neighbor soldier armenians afraid armenian mother hide town alive\n",
      "christianity christian sin bible scripture revelation god pray eternal heaven\n",
      "professor armenian turkish francisco jews foreign village angeles escape genocide\n",
      "christ jesus verse scripture lord prophet pray rise god heaven\n",
      "jpeg gif mirror setting image pixel compression format color vendor\n",
      "annual dos print rider origin shipping app copy justice battle\n",
      "ide scsus isa scsi bus mhz cache pc cpu os\n",
      "war armenian nuclear stephanopoulos job president town azerbaijan economy ship\n",
      "binary dec workstation vendor postscript platform export database plot mit\n",
      "homicide violent militia seattle handgun gun rate firearm assault arm\n",
      "libertarian insurance violent gun federal regulation economy criminal health weapon\n",
      "connector pin audio amp voltage motherboard switch signal ide supply\n",
      "pitch hitter defensive offense braves ball pitcher ford season score\n",
      "president stephanopoulos secretary economy budget yesterday morning prepare economic meeting\n",
      "defensive stats braves offense roger hitter player team pitcher coach\n",
      "crypto nsa escrow wiretap clipper warrant rf radar brad detector\n",
      "jumper floppy connector pin drive bio adapter rom ram vga\n",
      "mw bhj wm sl pl mr mg rg pd eus\n",
      "hello fax advance email brand appreciate music thanks australia thank\n",
      "printer vga unit print monitor link cross gateway windows postscript\n",
      "mouse gateway quadra microsoft apple inch jump monitor ball screen\n",
      "doctrine holy scripture tradition catholic god christ christian church spirit\n",
      "motherboard apple adapter boot shipping brand connector slot kit pin\n",
      "arab lebanon israel israeli civilian sexual arabs homosexual marriage sex\n",
      "pit tor cal det que min van nj mon buf\n",
      "radar detector brake motor gun insurance gear detect plant engine\n",
      "enforcement escrow serial security clipper encrypt agency encryption chip nsa\n",
      "colormap byte null db int bh button xterm map color\n",
      "uucp stats _eos_ ignorance atlanta marc programmer advance appreciate anybody\n",
      "wings leafs stanley playoff puck pp montreal penalty goal pittsburgh\n",
      "swap cache converter ram xt widget default xlib os root\n",
      "database solar nasa map image spacecraft processing plot virtual observe\n",
      "encryption enforcement health manufacture disease age economic volume security agency\n",
      "solar nasa rocket space spacecraft flight soviet mission observe earth\n",
      "ride helmet rider cop dog msg accident rear bike gear\n",
      "batf compound fbi cult koresh fire tear waco camera justify\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  1112.470496120018\n"
     ]
    }
   ],
   "source": [
    "emb = model.de.linear.weight.data.cpu().numpy().T\n",
    "print_top_words(emb, list(zip(*sorted(vocab.items(), key=lambda x:x[1])))[0])\n",
    "print_perp(model)\n",
    "# visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-avitm-1.0",
   "language": "python",
   "name": "pt-avitm-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
