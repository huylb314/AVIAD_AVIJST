{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install https://download.pytorch.org/whl/cu75/torch-0.1.12.post1-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from pprint import pprint, pformat\n",
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProdLDA(nn.Module):\n",
    "\n",
    "    def __init__(self, net_arch):\n",
    "        super(ProdLDA, self).__init__()\n",
    "        ac = net_arch\n",
    "        self.net_arch = net_arch\n",
    "        # encoder\n",
    "        self.en1_fc     = nn.Linear(ac.num_input, ac.en1_units)             # 1995 -> 100\n",
    "        self.en2_fc     = nn.Linear(ac.en1_units, ac.en2_units)             # 100  -> 100\n",
    "        self.en2_drop   = nn.Dropout(0.2)\n",
    "        self.mean_fc    = nn.Linear(ac.en2_units, ac.num_topic)             # 100  -> 50\n",
    "        self.mean_bn    = nn.BatchNorm1d(ac.num_topic)                      # bn for mean\n",
    "        self.logvar_fc  = nn.Linear(ac.en2_units, ac.num_topic)             # 100  -> 50\n",
    "        self.logvar_bn  = nn.BatchNorm1d(ac.num_topic)                      # bn for logvar\n",
    "        # z\n",
    "        self.p_drop     = nn.Dropout(0.2)\n",
    "        # decoder\n",
    "        self.decoder    = nn.Linear(ac.num_topic, ac.num_input)             # 50   -> 1995\n",
    "        self.decoder_bn = nn.BatchNorm1d(ac.num_input)                      # bn for decoder\n",
    "        # prior mean and variance as constant buffers\n",
    "        prior_mean   = torch.Tensor(1, ac.num_topic).fill_(0)\n",
    "        prior_var    = torch.Tensor(1, ac.num_topic).fill_(ac.variance)\n",
    "        prior_logvar = prior_var.log()\n",
    "        self.register_buffer('prior_mean',    prior_mean)\n",
    "        self.register_buffer('prior_var',     prior_var)\n",
    "        self.register_buffer('prior_logvar',  prior_logvar)\n",
    "        # initialize decoder weight\n",
    "        if ac.init_mult != 0:\n",
    "            #std = 1. / math.sqrt( ac.init_mult * (ac.num_topic + ac.num_input))\n",
    "            self.decoder.weight.data.uniform_(0, ac.init_mult)\n",
    "        # remove BN's scale parameters\n",
    "        self.logvar_bn .register_parameter('weight', None)\n",
    "        self.mean_bn   .register_parameter('weight', None)\n",
    "        self.decoder_bn.register_parameter('weight', None)\n",
    "        self.decoder_bn.register_parameter('weight', None)\n",
    "\n",
    "    def forward(self, input, compute_loss=False, avg_loss=True):\n",
    "        # compute posterior\n",
    "        en1 = F.softplus(self.en1_fc(input))                            # en1_fc   output\n",
    "        en2 = F.softplus(self.en2_fc(en1))                              # encoder2 output\n",
    "        en2 = self.en2_drop(en2)\n",
    "        posterior_mean   = self.mean_bn  (self.mean_fc  (en2))          # posterior mean\n",
    "        posterior_logvar = self.logvar_bn(self.logvar_fc(en2))          # posterior log variance\n",
    "        posterior_var    = posterior_logvar.exp()\n",
    "        # take sample\n",
    "        eps = Variable(input.data.new().resize_as_(posterior_mean.data).normal_()) # noise\n",
    "        z = posterior_mean + posterior_var.sqrt() * eps                 # reparameterization\n",
    "        p = F.softmax(z)                                                # mixture probability\n",
    "        p = self.p_drop(p)\n",
    "        # do reconstruction\n",
    "        recon = F.softmax(self.decoder_bn(self.decoder(p)))             # reconstructed distribution over vocabulary\n",
    "\n",
    "        if compute_loss:\n",
    "            return recon, self.loss(input, recon, posterior_mean, posterior_logvar, posterior_var, avg_loss)\n",
    "        else:\n",
    "            return recon\n",
    "\n",
    "    def loss(self, input, recon, posterior_mean, posterior_logvar, posterior_var, avg=True):\n",
    "        # NL\n",
    "        NL  = -(input * (recon+1e-10).log()).sum(1)\n",
    "        # KLD, see Section 3.3 of Akash Srivastava and Charles Sutton, 2017, \n",
    "        # https://arxiv.org/pdf/1703.01488.pdf\n",
    "        prior_mean   = Variable(self.prior_mean).expand_as(posterior_mean)\n",
    "        prior_var    = Variable(self.prior_var).expand_as(posterior_mean)\n",
    "        prior_logvar = Variable(self.prior_logvar).expand_as(posterior_mean)\n",
    "        var_division    = posterior_var  / prior_var\n",
    "        diff            = posterior_mean - prior_mean\n",
    "        diff_term       = diff * diff / prior_var\n",
    "        logvar_division = prior_logvar - posterior_logvar\n",
    "        # put KLD together\n",
    "        KLD = 0.5 * ( (var_division + diff_term + logvar_division).sum(1) - self.net_arch.num_topic )\n",
    "        # loss\n",
    "        loss = (NL + KLD)\n",
    "        # in traiming mode, return averaged loss. In testing mode, return individual loss\n",
    "        if avg:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(data, min_length):\n",
    "    return np.bincount(data, minlength=min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perp(model):\n",
    "    cost=[]\n",
    "    model.eval()                        # switch to testing mode\n",
    "    input = Variable(tensor_te)\n",
    "    recon, loss = model(input, compute_loss=True, avg_loss=False)\n",
    "    loss = loss.data\n",
    "    counts = tensor_te.sum(1)\n",
    "    avg = (loss / counts).mean()\n",
    "    print('The approximated perplexity is: ', math.exp(avg))\n",
    "\n",
    "def visualize():\n",
    "    global recon\n",
    "    input = Variable(tensor_te[:10])\n",
    "    register_vis_hooks(model)\n",
    "    recon = model(input, compute_loss=False)\n",
    "    remove_vis_hooks()\n",
    "    save_visualization('pytorch_model', 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tr = 'data/20news_clean/train.txt.npy'\n",
    "data_tr = np.load(dataset_tr, encoding=\"latin1\")\n",
    "dataset_te = 'data/20news_clean/test.txt.npy'\n",
    "data_te = np.load(dataset_te, encoding=\"latin1\")\n",
    "vocab = 'data/20news_clean/vocab.pkl'\n",
    "vocab_file = open(vocab,'rb')\n",
    "vocab = pickle.load(vocab_file)\n",
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data to one-hot representation\n",
      "Data Loaded\n",
      "Dim Training Data (11258, 1995)\n",
      "Dim Test Data (7487, 1995)\n"
     ]
    }
   ],
   "source": [
    "#--------------convert to one-hot representation------------------\n",
    "print ('Converting data to one-hot representation')\n",
    "data_tr = np.array([to_onehot(doc.astype('int'),vocab_size) for doc in data_tr if np.sum(doc)!=0])\n",
    "data_te = np.array([to_onehot(doc.astype('int'),vocab_size) for doc in data_te if np.sum(doc)!=0])\n",
    "#--------------print the data dimentions--------------------------\n",
    "print ('Data Loaded')\n",
    "print ('Dim Training Data', data_tr.shape)\n",
    "print ('Dim Test Data', data_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------make tensor datasets-------------------------------\n",
    "tensor_tr = torch.from_numpy(data_tr).float()\n",
    "tensor_te = torch.from_numpy(data_te).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    en1_units=100\n",
    "    en2_units=100\n",
    "    num_topic=50\n",
    "    num_input=1995\n",
    "    variance=0.995\n",
    "    init_mult=1.0\n",
    "    learning_rate=0.002\n",
    "    batch_size=200\n",
    "    momentum=0.99\n",
    "    num_epoch=80\n",
    "    nogpu=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch = args # en1_units, en2_units, num_topic, num_input\n",
    "net_arch.num_input = data_tr.shape[1]\n",
    "model = ProdLDA(net_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "# optimizer = torch.optim.SGD(model.parameters(), args.learning_rate, momentum=args.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=752.4367258172286\n",
      "Epoch 5, loss=675.5377936112253\n",
      "Epoch 10, loss=660.8357276247259\n",
      "Epoch 15, loss=658.2979083144874\n",
      "Epoch 20, loss=644.949268541838\n",
      "Epoch 25, loss=636.1256954795435\n",
      "Epoch 30, loss=630.2199583890146\n",
      "Epoch 35, loss=625.2974773206209\n",
      "Epoch 40, loss=621.7331098589981\n",
      "Epoch 45, loss=623.0270417865954\n",
      "Epoch 50, loss=618.1221174273575\n",
      "Epoch 55, loss=616.5587902403714\n",
      "Epoch 60, loss=613.2184491073876\n",
      "Epoch 65, loss=611.7819711785568\n",
      "Epoch 70, loss=610.1798170658581\n",
      "Epoch 75, loss=612.7063925224438\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.num_epoch):\n",
    "    all_indices = torch.randperm(tensor_tr.size(0)).split(args.batch_size)\n",
    "    loss_epoch = 0.0\n",
    "    model.train()                   # switch to training mode\n",
    "    for batch_indices in all_indices:\n",
    "#         if not args.nogpu: batch_indices = batch_indices.cuda()\n",
    "        input = Variable(tensor_tr[batch_indices])\n",
    "        recon, loss = model(input, compute_loss=True)\n",
    "        # optimize\n",
    "        optimizer.zero_grad()       # clear previous gradients\n",
    "        loss.backward()             # backprop\n",
    "        optimizer.step()            # update parameters\n",
    "        # report\n",
    "        loss_epoch += loss.data[0]    # add loss to loss_epoch\n",
    "    if epoch % 5 == 0:\n",
    "        print('Epoch {}, loss={}'.format(epoch, loss_epoch / len(all_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perp(model):\n",
    "    cost=[]\n",
    "    model.eval()                        # switch to testing mode\n",
    "    input = Variable(tensor_te)\n",
    "    recon, loss = model(input, compute_loss=True, avg_loss=False)\n",
    "    loss = loss.data\n",
    "    counts = tensor_te.sum(1)\n",
    "    avg = (loss / counts).mean()\n",
    "    print('The approximated perplexity is: ', math.exp(avg))\n",
    "\n",
    "def visualize():\n",
    "    global recon\n",
    "    input = Variable(tensor_te[:10])\n",
    "    register_vis_hooks(model)\n",
    "    recon = model(input, compute_loss=False)\n",
    "    remove_vis_hooks()\n",
    "    save_visualization('pytorch_model', 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_topic_in_line(line):\n",
    "    topics = []\n",
    "    for topic, keywords in associations.items():\n",
    "        for word in keywords:\n",
    "            if word in line:\n",
    "                topics.append(topic)\n",
    "                break\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(beta, feature_names, n_top_words=10):\n",
    "    print ('---------------Printing the Topics------------------')\n",
    "    for i in range(len(beta)):\n",
    "        line = \" \".join([feature_names[j] \n",
    "                            for j in beta[i].argsort()[:-n_top_words - 1:-1]])\n",
    "        topics = identify_topic_in_line(line)\n",
    "        print('|'.join(topics))\n",
    "        print('     {}'.format(line))\n",
    "    print ('---------------End of Topics------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "associations = {\n",
    "    'jesus': ['prophet', 'jesus', 'matthew', 'christ', 'worship', 'church'],\n",
    "    'comp ': ['floppy', 'windows', 'microsoft', 'monitor', 'workstation', 'macintosh', \n",
    "              'printer', 'programmer', 'colormap', 'scsi', 'jpeg', 'compression'],\n",
    "    'car  ': ['wheel', 'tire'],\n",
    "    'polit': ['amendment', 'libert', 'regulation', 'president'],\n",
    "    'crime': ['violent', 'homicide', 'rape'],\n",
    "    'midea': ['lebanese', 'israel', 'lebanon', 'palest'],\n",
    "    'sport': ['coach', 'hitter', 'pitch'],\n",
    "    'gears': ['helmet', 'bike'],\n",
    "    'nasa ': ['orbit', 'spacecraft'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Printing the Topics------------------\n",
      "comp \n",
      "     scsus floppy jumper scsi controller microsoft backup cache disk ram\n",
      "jesus\n",
      "     turks armenians armenian village troops town massacre jesus azerbaijan turkish\n",
      "\n",
      "     anonymous electronic digital internet service account site amiga abuse responsibility\n",
      "\n",
      "     batf compound waco insurance country kid fbi clinton cop assault\n",
      "polit\n",
      "     militia sentence constitution amendment arm shall weapon organize regulation states\n",
      "\n",
      "     amp speaker cd dos shipping remote adapter audio channel manual\n",
      "\n",
      "     det tor min pit nj cal que mon buf calgary\n",
      "\n",
      "     gm mw wings st wm mg md vs rangers june\n",
      "midea\n",
      "     arab israel arabs palestinian jews israeli jew francisco territory land\n",
      "gears\n",
      "     honda bike helmet gear mouse rear ford ride craig front\n",
      "jesus\n",
      "     religious atheism catholic doctrine atheist tradition pope church teaching god\n",
      "\n",
      "     wire connector panel outlet wiring cable connect jumper ground pin\n",
      "\n",
      "     armenia armenians art massacre montreal atlanta annual village bh mountain\n",
      "jesus\n",
      "     jesus heaven prayer christ satan eternal god koresh sin kent\n",
      "nasa \n",
      "     processing pm amiga analysis mission graphics spacecraft platform database module\n",
      "jesus\n",
      "     jesus god doctrine christ resurrection bible son biblical mary scripture\n",
      "nasa \n",
      "     launch mission space spacecraft water rocket participate nasa satellite vehicle\n",
      "\n",
      "     mouse gateway quadra modem motherboard switch meg hd simm setup\n",
      "\n",
      "     montreal boston calgary wings stanley period winnipeg ottawa leafs pp\n",
      "\n",
      "     turks armenian armenians genocide armenia muslim turkish village massacre muslims\n",
      "\n",
      "     cancer md laboratory february journal senior states director staff culture\n",
      "\n",
      "     variable winner remark entry submit contest rule client menu prior\n",
      "sport\n",
      "     penalty pitch defensive season offense team injury career hitter defense\n",
      "jesus\n",
      "     truth moral absolute christianity morality scripture god interpretation belief sex\n",
      "\n",
      "     mw pl rg wm sl mi mg bhj hd mr\n",
      "sport\n",
      "     pitcher defensive hitter braves player offense baseball team pitch career\n",
      "\n",
      "     dec motif vendor electronic toolkit terminal mailing request mit anonymous\n",
      "\n",
      "     afraid armenians apartment alive troops floor town february walk tear\n",
      "nasa \n",
      "     mission spacecraft saturn km launch shuttle orbit rocket flight lunar\n",
      "\n",
      "     escrow rsa key serial wiretap enforcement nsa algorithm encrypt clipper\n",
      "\n",
      "     june shipping speaker sale electronic brand price manual papers interested\n",
      "\n",
      "     printf remark contest io postscript stream echo oname exit buffer\n",
      "comp \n",
      "     dos gateway modem motherboard cd setup monitor card video hello\n",
      "gears\n",
      "     bike cop ride accident dog rider helmet gang msg training\n",
      "midea\n",
      "     village lebanese lebanon arab israel troops civilian arabs israeli terrorist\n",
      "\n",
      "     uucp thanks thank institute _eos_ australia advance sale interested hello\n",
      "\n",
      "     uucp surrender _eos_ gordon larry arabs phil ignorance write marc\n",
      "comp \n",
      "     scsus scsi isa ide quadra meg hd controller motherboard bus\n",
      "\n",
      "     surrender gordon joke article bank write ignorance phil curious kent\n",
      "comp \n",
      "     hello floppy thanks hus uucp advance doug microsoft greatly sale\n",
      "comp \n",
      "     scsus motherboard scsi connector ide floppy hd adapter isa quadra\n",
      "\n",
      "     congress secretary summer senior stephanopoulos specific february country russian job\n",
      "car  \n",
      "     gear tire brake amp wheel motor component ab nec wire\n",
      "\n",
      "     ripem rsa encrypt key visual random cipher algorithm des map\n",
      "\n",
      "     bh db motif al pop graphics postscript lower ah mov\n",
      "\n",
      "     encryption wiretap enforcement escrow criminal economic communication secure americans agency\n",
      "\n",
      "     morality moral observation science existence observe scientific animal atheism scientist\n",
      "\n",
      "     visual xt xlib motif window vendor default application toolkit converter\n",
      "crime\n",
      "     insurance homicide violent seattle hospital vancouver health md risk cite\n",
      "gears\n",
      "     gear honda bike amp helmet battery engine rear ford saturn\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  1136.8170632960791\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tpng', '-O', 'pytorch_model'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-avitm/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch-avitm/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b08cd922c6df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint_top_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint_perp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-8e8152286d06>\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mremove_vis_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0msave_visualization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/huylb314/Shared Data/huylb/Drive Files/Assets/My Projects/ML/prob/pytorch-avitm/pytorch_visualize.py\u001b[0m in \u001b[0;36msave_visualization\u001b[0;34m(name, format)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_trace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, filename, directory, view, cleanup)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mrendered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, quiet)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \"\"\"\n\u001b[1;32m    141\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrendered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrendered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tpng', '-O', 'pytorch_model'], make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "emb = model.decoder.weight.data.cpu().numpy().T\n",
    "print_top_words(emb, list(zip(*sorted(vocab.items(), key=lambda x:x[1])))[0])\n",
    "print_perp(model)\n",
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python(avi)",
   "language": "python",
   "name": "avi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
