{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "from sklearn import datasets\n",
    "from numpy import random\n",
    "from scipy.stats import dirichlet, norm, poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import reuters, imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Path.ls = lambda x: list(x.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URSA Datasets 1K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_ds_path = Path('../data/User Review Structure Analysis (URSA)/')\n",
    "xml_path = (folder_ds_path/'Classified_Corpus.xml')\n",
    "ds_path = (folder_ds_path/'1k')\n",
    "sentence_npy_path = (folder_ds_path/'sentence.npy')\n",
    "vocab_pkl_path = (ds_path/'vocab.pkl')\n",
    "seed_words_path = (ds_path/'seed_words.txt')\n",
    "train_filename = (ds_path/'train.txt.npy')\n",
    "\n",
    "# log words not pass\n",
    "aspect_tags = ['Food', 'Staff', 'Ambience']\n",
    "polatiry_tags = ['Positive', 'Negative', 'Neutral']\n",
    "xml_review_tag = './/Review'\n",
    "log_np = [[], [], []]\n",
    "\n",
    "# length allowed sentences\n",
    "# length_allowed = [11, 7, 4]\n",
    "# min_freq_allowed = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2id = pickle.load(open(vocab_pkl_path, 'rb'))\n",
    "vocab_size=len(vocab2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load((train_filename), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sentence_list, label_list = train_data[:, 0], train_data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict(map(reversed, vocab2id.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_, y_ = [], []\n",
    "for p_sentence, label_ in zip(p_sentence_list, label_list): \n",
    "    x_.append(p_sentence)\n",
    "    y_.append(label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_) == len(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y =  train_test_split(\n",
    "    x_, y_, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n",
      "Dim Training Data 3095 2772\n",
      "Dim Test Data 344 2772\n"
     ]
    }
   ],
   "source": [
    "print ('Data Loaded')\n",
    "print ('Dim Training Data',len(train_x), vocab_size)\n",
    "print ('Dim Test Data', len(test_x), vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 200\n",
    "en1_units=100\n",
    "en2_units=100\n",
    "num_topic=3\n",
    "num_input=vocab_size\n",
    "variance=0.995\n",
    "init_mult=1.0\n",
    "learning_rate=0.0005\n",
    "batch_size=200\n",
    "momentum=0.99\n",
    "num_epoch=200\n",
    "nogpu=True\n",
    "drop_rate=0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_seed_words(fn):\n",
    "    with open(fn, \"r\") as fr:\n",
    "        def p_string_sw(l):\n",
    "            return l.replace('\\n','').split(',')\n",
    "        rl = [p_string_sw(l) for l in fr]\n",
    "    return rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_words = read_file_seed_words(seed_words_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['food', 'sauc', 'chicken', 'shrimp', 'chees', 'potato', 'fri', 'tomato', 'roast', 'onion', 'pork', 'goat', 'grill', 'tuna', 'salad', 'beef', 'tapa'], ['staff', 'servic', 'friendli', 'rude', 'hostess', 'waiter', 'bartend', 'waitress', 'help', 'polit', 'bar', 'courteou', 'member', 'waitstaff', 'attitud', 'reserv', 'tip'], ['atmospher', 'scene', 'place', 'tabl', 'outsid', 'area', 'ambianc', 'outdoor', 'romant', 'cozi', 'decor', 'sit', 'wall', 'light', 'window', 'area', 'ceil', 'floor']]\n"
     ]
    }
   ],
   "source": [
    "print (seed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_prior(fn, n_k=3):\n",
    "    gamma = torch.zeros((len(vocab),n_k))\n",
    "    gamma_bin = torch.zeros((1, len(vocab),n_k))\n",
    "\n",
    "    full_vocab = read_file_seed_words(fn)\n",
    "    for k in range(len(full_vocab)):\n",
    "        for idx in range(len(full_vocab[k])):\n",
    "            ivocab = vocab2id[full_vocab[k][idx]]\n",
    "            gamma[ivocab, k] = 1.0\n",
    "            gamma_bin[:, ivocab, :] = 1.0\n",
    "\n",
    "    return (gamma, gamma_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]\n",
    "def setify(o): return o if isinstance(o,set) else set(listify(o))\n",
    "def compose(x, funcs, *args, order_key='_order', **kwargs):\n",
    "    key = lambda o: getattr(o, order_key, 0)\n",
    "    for f in sorted(listify(funcs), key=key): x = f(x, **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perp(model):\n",
    "    cost = []\n",
    "    model.eval()                        # switch to testing mode\n",
    "    for x_test, y_test in test_dl:\n",
    "        recon, loss = model(x_test, compute_loss=True, avg_loss=False)\n",
    "        loss = loss.data\n",
    "        counts = x_test.sum(1)\n",
    "        cost.extend((loss / counts).data.cpu().tolist())\n",
    "    print('The approximated perplexity is: ', (np.exp(np.mean(np.array(cost)))))\n",
    "\n",
    "def print_top_words(beta, feature_names, n_top_words=10):\n",
    "    print ('---------------Printing the Topics------------------')\n",
    "    for i in range(len(beta)):\n",
    "        line = \" \".join([feature_names[j] \n",
    "                         for j in beta[i].argsort()[:-n_top_words - 1:-1]])\n",
    "        print('{}'.format(line))\n",
    "    print ('---------------End of Topics------------------')\n",
    "    \n",
    "def print_gamma(gamma, seed_words, vocab, vocab2id):\n",
    "    sws = []        \n",
    "    for k in range(len(seed_words)):\n",
    "        for idx in range(len(seed_words[k])):\n",
    "            w = seed_words[k][idx]\n",
    "            sws.append((k, w))\n",
    "\n",
    "    for idx in range(len(sws)):\n",
    "        k, w = sws[idx]\n",
    "        ivocab = vocab2id[w]\n",
    "        mk = gamma[ivocab].argmax(-1)\n",
    "        print (ivocab, w, k, mk, gamma[ivocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    x, y = zip(*b)\n",
    "    return torch.stack(x), torch.stack(y)\n",
    "\n",
    "class IdifyAndLimitedVocab():\n",
    "    _order=-1\n",
    "    def __init__(self, vocab2id, limited_vocab):\n",
    "        self.vocab2id = vocab2id\n",
    "        self.limited_vocab = limited_vocab\n",
    "    def __call__(self, item):\n",
    "        idlist = [self.vocab2id[w] for w in item if self.vocab2id[w] < self.limited_vocab]\n",
    "        return np.array(idlist)\n",
    "    \n",
    "\n",
    "class Numpyify():\n",
    "    _order=0\n",
    "    def __call__(self, item):\n",
    "        return np.array(item)\n",
    "\n",
    "class Onehotify():\n",
    "    _order=1\n",
    "    def __init__(self, vocab_size):\n",
    "        self.vocab_size = vocab_size\n",
    "    def __call__(self, item):\n",
    "        return np.array(np.bincount(item.astype('int'), minlength=self.vocab_size))\n",
    "    \n",
    "class YToOnehot():\n",
    "    _order=1\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "    def __call__(self, item):\n",
    "        categorical = np.zeros((1, self.num_classes))\n",
    "        categorical[0, item] = 1\n",
    "        return categorical\n",
    "\n",
    "class Tensorify():\n",
    "    _order=2\n",
    "    def __call__(self, item):\n",
    "        return torch.from_numpy(item)\n",
    "\n",
    "class Floatify():\n",
    "    _order=3\n",
    "    def __call__(self, item):\n",
    "        return item.float()\n",
    "    \n",
    "class CheckAndCudify():\n",
    "    _order=100\n",
    "    def __init__(self):\n",
    "        self.ic = torch.cuda.is_available()\n",
    "    def __call__(self, item):\n",
    "        return item.cuda() if self.ic else item\n",
    "    \n",
    "class URSADataset(Dataset):\n",
    "    def __init__(self, x, y, tfms_x, tfms_y): \n",
    "        self.x, self.y = x, y\n",
    "        self.x_tfms = tfms_x\n",
    "        self.y_tfms = tfms_y\n",
    "    def __len__(self): \n",
    "        return len(self.x)\n",
    "    def __getitem__(self, i): \n",
    "        return compose(self.x[i], self.x_tfms), compose(self.y[i], self.y_tfms)\n",
    "    \n",
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, ds, sampler, collate_fn=collate):\n",
    "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(train_y) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms_x = [Numpyify(), Onehotify(vocab_size=vocab_size), Tensorify(), Floatify(), CheckAndCudify()]\n",
    "tfms_y = [YToOnehot(num_classes=num_classes), Tensorify(), Floatify(), CheckAndCudify()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = URSADataset(train_x, train_y, tfms_x=tfms_x, tfms_y=tfms_y)\n",
    "test_ds = URSADataset(test_x, test_y, tfms_x=tfms_x, tfms_y=tfms_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = Sampler(train_ds, bs, shuffle=False)\n",
    "test_samp = Sampler(test_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
    "test_dl = DataLoader(test_ds, sampler=test_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_prior = setup_prior(seed_words_path, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma, gamma_bin = gamma_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProdLDA(nn.Module):\n",
    "    def __init__(self, num_input, en1_units, en2_units, num_topic, drop_rate, init_mult, gamma_prior):\n",
    "        super(ProdLDA, self).__init__()\n",
    "        self.num_input, self.en1_units, self.en2_units, \\\n",
    "        self.num_topic, self.drop_rate, self.init_mult = num_input, en1_units, en2_units, \\\n",
    "                                                            num_topic, drop_rate, init_mult\n",
    "        # gamma prior\n",
    "        self.gamma_prior = gamma_prior\n",
    "        \n",
    "        # encoder\n",
    "        self.en1_fc = nn.Linear(num_input, en1_units)\n",
    "        self.en1_ac = nn.Softplus()\n",
    "        self.en2_fc     = nn.Linear(en1_units, en2_units)\n",
    "        self.en2_ac = nn.Softplus()\n",
    "        self.en2_dr   = nn.Dropout(drop_rate)\n",
    "        \n",
    "        # mean, logvar\n",
    "        self.mean_fc = nn.Linear(en2_units, num_topic)\n",
    "        self.mean_bn = nn.BatchNorm1d(num_topic)\n",
    "        self.logvar_fc = nn.Linear(en2_units, num_topic)\n",
    "        self.logvar_bn = nn.BatchNorm1d(num_topic)\n",
    "\n",
    "        # decoder\n",
    "        self.de_ac1 = nn.Softmax(dim=-1)\n",
    "        self.de_dr = nn.Dropout(drop_rate)\n",
    "        self.de_fc = nn.Linear(num_topic, num_input)\n",
    "        self.de_bn = nn.BatchNorm1d(num_input)\n",
    "        self.de_ac2 = nn.Softmax(dim=-1)\n",
    "        \n",
    "        # prior mean and variance as constant buffers\n",
    "        self.prior_mean   = torch.Tensor(1, num_topic).fill_(0)\n",
    "        self.prior_var    = torch.Tensor(1, num_topic).fill_(variance)\n",
    "        self.prior_mean   = nn.Parameter(self.prior_mean, requires_grad=False)\n",
    "        self.prior_var    = nn.Parameter(self.prior_var, requires_grad=False)\n",
    "        self.prior_logvar = nn.Parameter(self.prior_var.log(), requires_grad=False)\n",
    "        # initialize decoder weight\n",
    "        if init_mult != 0:\n",
    "            #std = 1. / math.sqrt( init_mult * (num_topic + num_input))\n",
    "            self.de_fc.weight.data.uniform_(0, init_mult)\n",
    "        # remove BN's scale parameters\n",
    "        for component in [self.mean_bn, self.logvar_bn, self.de_bn]:\n",
    "            component.weight.requires_grad = False\n",
    "            component.weight.fill_(1.0)\n",
    "        \n",
    "    def gamma(self):\n",
    "        # this function have to run after self.encode\n",
    "        encoder_w1 = self.en1_fc.weight\n",
    "        encoder_b1 = self.en1_fc.bias\n",
    "        encoder_w2 = self.en2_fc.weight\n",
    "        encoder_b2 = self.en2_fc.bias\n",
    "        mean_w = self.mean_fc.weight\n",
    "        mean_b = self.mean_fc.bias\n",
    "        mean_running_mean = self.mean_bn.running_mean\n",
    "        mean_running_var = self.mean_bn.running_var\n",
    "        logvar_w = self.logvar_fc.weight\n",
    "        logvar_b = self.logvar_fc.bias\n",
    "        logvar_running_mean = self.logvar_bn.running_mean\n",
    "        logvar_running_var = self.logvar_bn.running_var\n",
    "        \n",
    "        w1 = F.softplus(encoder_w1.t() + encoder_b1)\n",
    "        w2 = F.softplus(F.linear(w1, encoder_w2, encoder_b2))\n",
    "        wdr = F.dropout(w2, self.drop_rate)\n",
    "        wo_mean = F.softmax(F.linear(wdr, mean_w, mean_b), dim=-1)\n",
    "        wo_logvar = F.softmax(F.batch_norm(F.linear(wdr, logvar_w, logvar_b), logvar_running_mean, logvar_running_var), dim=-1)\n",
    "        \n",
    "        return wo_mean, wo_logvar\n",
    "            \n",
    "    def encode(self, input_):\n",
    "        # encoder\n",
    "        encoded1 = self.en1_fc(input_)\n",
    "        encoded1_ac = self.en1_ac(encoded1)\n",
    "        encoded2 = self.en2_fc(encoded1_ac)\n",
    "        encoded2_ac = self.en2_ac(encoded2)\n",
    "        encoded2_dr = self.en2_dr(encoded2_ac)\n",
    "        \n",
    "        encoded = encoded2_dr\n",
    "        \n",
    "        # hidden => mean, logvar\n",
    "        mean_theta = self.mean_fc(encoded)\n",
    "        mean_theta_bn = self.mean_bn(mean_theta)\n",
    "        logvar_theta = self.logvar_fc(encoded)\n",
    "        logvar_theta_bn = self.logvar_bn(logvar_theta)\n",
    "        \n",
    "        posterior_mean = mean_theta_bn\n",
    "        posterior_logvar = logvar_theta_bn\n",
    "        return encoded, posterior_mean, posterior_logvar\n",
    "    \n",
    "    def decode(self, input_, posterior_mean, posterior_var):\n",
    "        # take sample\n",
    "        eps = input_.data.new().resize_as_(posterior_mean.data).normal_() # noise \n",
    "        z = posterior_mean + posterior_var.sqrt() * eps                   # reparameterization\n",
    "        # do reconstruction\n",
    "        # decoder\n",
    "        decoded1_ac = self.de_ac1(z)\n",
    "        decoded1_dr = self.de_dr(decoded1_ac)\n",
    "        decoded2 = self.de_fc(decoded1_dr)\n",
    "        decoded2_bn = self.de_bn(decoded2)\n",
    "        decoded2_ac = self.de_ac2(decoded2_bn)\n",
    "        recon = decoded2_ac          # reconstructed distribution over vocabulary\n",
    "        return recon\n",
    "    \n",
    "    def forward(self, input_, compute_loss=False, avg_loss=True):\n",
    "        # compute posterior\n",
    "        en2, posterior_mean, posterior_logvar = self.encode(input_) \n",
    "        posterior_var    = posterior_logvar.exp()\n",
    "        \n",
    "        recon = self.decode(input_, posterior_mean, posterior_var)\n",
    "        if compute_loss:\n",
    "            return recon, self.loss(input_, recon, posterior_mean, posterior_logvar, posterior_var, avg_loss)\n",
    "        else:\n",
    "            return recon\n",
    "\n",
    "    def loss(self, input_, recon, posterior_mean, posterior_logvar, posterior_var, avg=True):\n",
    "        # NL\n",
    "        NL  = -(input_ * (recon + 1e-10).log()).sum(1)\n",
    "        # KLD, see Section 3.3 of Akash Srivastava and Charles Sutton, 2017, \n",
    "        # https://arxiv.org/pdf/1703.01488.pdf\n",
    "        prior_mean   = self.prior_mean.expand_as(posterior_mean)\n",
    "        prior_var    = self.prior_var.expand_as(posterior_mean)\n",
    "        prior_logvar = self.prior_logvar.expand_as(posterior_mean)\n",
    "        var_division    = posterior_var  / prior_var\n",
    "        diff            = posterior_mean - prior_mean\n",
    "        diff_term       = diff * diff / prior_var\n",
    "        logvar_division = prior_logvar - posterior_logvar\n",
    "        # put KLD together\n",
    "        KLD = 0.5 * ( (var_division + diff_term + logvar_division).sum(1) - self.num_topic)\n",
    "        \n",
    "        # gamma\n",
    "        n, _ = input_.size()\n",
    "        gamma_mean, gamma_logvar = self.gamma()\n",
    "        gamma_prior, gammar_prior_bin = self.gamma_prior\n",
    "        input_t = (input_ > 0).unsqueeze(dim=-1)\n",
    "        input_bin = ((gammar_prior_bin.expand(n, -1, -1) == 1) & input_t)\n",
    "        lambda_c = 20.0\n",
    "        \n",
    "        gamma_prior = gamma_prior.expand(n, -1, -1)      \n",
    "        \n",
    "        GL = lambda_c * ((gamma_prior - (input_bin.int()*gamma_mean))**2).sum((1, 2))\n",
    "        \n",
    "        # loss\n",
    "        loss = (NL + KLD + GL)\n",
    "        \n",
    "        # in traiming mode, return averaged loss. In testing mode, return individual loss\n",
    "        if avg:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_true):\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1_score, _ = metrics.precision_recall_fscore_support(y_true=y_true, \\\n",
    "                                                     y_pred=y_pred, \\\n",
    "                                                     average=None)\n",
    "\n",
    "    return (accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProdLDA(num_input, en1_units, en2_units, num_topic, drop_rate, init_mult, gamma_prior)\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate, betas=(momentum, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huylb314/anaconda3/envs/avi/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch 0, loss=198.990478515625, accuracy_train=0.30823909531502425, accuracy_test=0.28488372093023256\n",
      "precision_train0 = 0.000000000 recall_train0 = 0.000000000 f1_score_train0 = 0.000000000\n",
      "precision_te0 = 0.000000000 recall_te0 = 0.000000000 f1_score_te0 = 0.000000000\n",
      "precision_train1 = 0.000000000 recall_train1 = 0.000000000 f1_score_train1 = 0.000000000\n",
      "precision_te1 = 0.000000000 recall_te1 = 0.000000000 f1_score_te1 = 0.000000000\n",
      "precision_train2 = 0.308239095 recall_train2 = 1.000000000 f1_score_train2 = 0.471227464\n",
      "precision_te2 = 0.284883721 recall_te2 = 1.000000000 f1_score_te2 = 0.443438914\n",
      "---------------Printing the Topics------------------\n",
      "somewher hood lime babi asid intim sprout ac poor cajun wrong solid importantli overhear model fluffi upon fusion notic mismatch foie noir ave conveni freshli purpl local pud serious mustard tall amus paid feta poster smile color complai drape piquant eggplant exud guac irrit oppos miss complimentari bruschetta incompet modern\n",
      "market citru said chicken buffet friend form game regret phone velveti companion somewher line cuba typic french within marri bisqu ether song spice behind finest gigant margarita stool quail candi even arugula fav refin spectacular eas pollo ideal parmigiano talent particular ask bottl dulc watch miss sea cod white bathroom\n",
      "pick second impecc abil despit take known abund desir travel eastern ambianc milkshak suck octopu pinot babi genuin nori hungri neither cool couldnt unpretenti hook consomm skylight seafood difficult extra pass spaetzl sandwich advantag asian esqu satay print portobello truli awhil bass occas subway piquant loung mine knock attent see\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  3.8139060786566927e+25\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 5, loss=198.6424380653783, accuracy_train=0.6455573505654281, accuracy_test=0.627906976744186\n",
      "precision_train0 = 0.845360825 recall_train0 = 0.309433962 f1_score_train0 = 0.453038674\n",
      "precision_te0 = 0.800000000 recall_te0 = 0.295081967 f1_score_te0 = 0.431137725\n",
      "precision_train1 = 0.737251513 recall_train1 = 0.789084181 f1_score_train1 = 0.762287757\n",
      "precision_te1 = 0.811475410 recall_te1 = 0.798387097 f1_score_te1 = 0.804878049\n",
      "precision_train2 = 0.527096774 recall_train2 = 0.856394130 f1_score_train2 = 0.652555911\n",
      "precision_te2 = 0.457627119 recall_te2 = 0.826530612 f1_score_te2 = 0.589090909\n",
      "---------------Printing the Topics------------------\n",
      "babi somewher ac model lime hood wrong foie pud freshli intim mismatch purpl piquant color eggplant miss smile upon notic fluffi amus serious fusion solid cajun ave sprout local poor importantli stew guy eastern paid modern asid incompet favourit king mustard photo feta exquisit drape plate noir conveni highli oppos\n",
      "market chicken said form behind gigant french friend even fav line ether game watch cod miss white cuba phone sea spice somewher buffet candi citru ask stool onto particular linen might refin typic strawberri velveti quit overal arugula margarita dulc daili finest vegetarian love bathroom within neighborhood quail pollo regret\n",
      "pick take octopu despit babi impecc second seafood suck milkshak known travel couldnt eastern pinot satay loung abil cool pass ambianc bass abund extra desir complaint see portobello print sandwich piquant genuin esqu asian attent food hungri block mar continu catfish occas subway amount mind truli eggplant advantag neither heart\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  3.3565464770170514e+25\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 10, loss=198.38570877878288, accuracy_train=0.6733441033925687, accuracy_test=0.7093023255813954\n",
      "precision_train0 = 0.567028986 recall_train0 = 0.885849057 f1_score_train0 = 0.691458027\n",
      "precision_te0 = 0.585106383 recall_te0 = 0.901639344 f1_score_te0 = 0.709677419\n",
      "precision_train1 = 0.743227326 recall_train1 = 0.583718779 f1_score_train1 = 0.653886010\n",
      "precision_te1 = 0.829787234 recall_te1 = 0.629032258 f1_score_te1 = 0.715596330\n",
      "precision_train2 = 0.871186441 recall_train2 = 0.538784067 f1_score_train2 = 0.665803109\n",
      "precision_te2 = 0.903225806 recall_te2 = 0.571428571 f1_score_te2 = 0.700000000\n",
      "---------------Printing the Topics------------------\n",
      "babi somewher foie ac model freshli piquant pud wrong color eggplant intim mismatch miss lime hood purpl smile amus eastern guy stew upon boomer highli serious notic king modern fluffi favourit exquisit disappoint photo solid seat duck ave deep buck would plate assort empti mussel cajun local fusion incompet market\n",
      "market chicken behind miss gigant even said form french watch fav cod friend sea line strawberri somewher spice white candi ask ether cuba phone game love onto neighborhood might particular linen peopl arugula quit overal daili refin stool buffet vegetarian citru bottl velveti filet typic peach dulc mar finest heart\n",
      "take pick octopu despit suck seafood babi milkshak impecc second eastern bass couldnt satay travel cool see known loung pass pinot abil food abund asian piquant complaint ambianc desir print extra esqu amount portobello heart sandwich block continu attent mar catfish deep occas eggplant purpl genuin subway ac mac tangi\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  3.183664245621741e+25\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 15, loss=198.10757606907896, accuracy_train=0.7369951534733441, accuracy_test=0.747093023255814\n",
      "precision_train0 = 0.722574796 recall_train0 = 0.751886792 f1_score_train0 = 0.736939436\n",
      "precision_te0 = 0.733870968 recall_te0 = 0.745901639 f1_score_te0 = 0.739837398\n",
      "precision_train1 = 0.776165803 recall_train1 = 0.692876966 f1_score_train1 = 0.732160313\n",
      "precision_te1 = 0.836363636 recall_te1 = 0.741935484 f1_score_te1 = 0.786324786\n",
      "precision_train2 = 0.715676728 recall_train2 = 0.770440252 f1_score_train2 = 0.742049470\n",
      "precision_te2 = 0.672727273 recall_te2 = 0.755102041 f1_score_te2 = 0.711538462\n",
      "---------------Printing the Topics------------------\n",
      "babi somewher foie ac color pud piquant freshli boomer model eggplant wrong mismatch guy intim eastern miss stew amus highli purpl smile hood deep duck lime king upon seat mussel would exquisit empti disappoint favourit liter photo pull notic assort plate buck market sour serious stuff modern perfect hop chorizo\n",
      "market miss chicken behind gigant even said watch form fav sea strawberri cod french somewher white friend ask peopl neighborhood spice love candi line onto cuba might ether overal phone particular quit arugula bottl linen filet daili game vegetarian peach refin stool substitut amus velveti mar heart typic incompet citru\n",
      "take pick octopu despit suck seafood bass babi eastern milkshak couldnt cool satay second see impecc travel asian food loung known piquant pass desir deep abund abil heart extra amount pinot eggplant complaint purpl print ambianc mac portobello silverwar esqu block men sweet continu tangi catfish sandwich mar ac choos\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  3.228586078450909e+25\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 20, loss=197.86529348273027, accuracy_train=0.7366720516962844, accuracy_test=0.75\n",
      "precision_train0 = 0.716431095 recall_train0 = 0.765094340 f1_score_train0 = 0.739963504\n",
      "precision_te0 = 0.726562500 recall_te0 = 0.762295082 f1_score_te0 = 0.744000000\n",
      "precision_train1 = 0.761133603 recall_train1 = 0.695652174 f1_score_train1 = 0.726921218\n",
      "precision_te1 = 0.827272727 recall_te1 = 0.733870968 f1_score_te1 = 0.777777778\n",
      "precision_train2 = 0.735384615 recall_train2 = 0.751572327 f1_score_train2 = 0.743390358\n",
      "precision_te2 = 0.698113208 recall_te2 = 0.755102041 f1_score_te2 = 0.725490196\n",
      "---------------Printing the Topics------------------\n",
      "babi somewher boomer foie color piquant pud freshli ac eggplant guy wrong eastern model duck liter stew deep miss intim highli mismatch mussel amus purpl smile would seat king pull market sour exquisit hood empti assort perfect upon lime favourit stuff photo disappoint chorizo cuba notic plate smell hop chandeli\n",
      "market miss behind even said chicken gigant watch form fav friend peopl ask white somewher cod sea strawberri onto spice neighborhood french love might overal bottl line ether particular cuba candi phone filet quit linen arugula substitut game vegetarian daili amus peach heart incompet freshli stool refin exquisit howev charm\n",
      "pick take despit suck octopu seafood bass cool eastern couldnt milkshak see travel babi second satay impecc asian piquant deep loung food desir known purpl mac pass abund eggplant amount silverwar heart extra complaint print men tangi ambianc abil sweet choos pinot block portobello continu ac sandwich lo subway esqu\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  3.104768314464435e+25\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch 25, loss=197.60438039679278, accuracy_train=0.7347334410339257, accuracy_test=0.7587209302325582\n",
      "precision_train0 = 0.709903593 recall_train0 = 0.764150943 f1_score_train0 = 0.736029078\n",
      "precision_te0 = 0.730769231 recall_te0 = 0.778688525 f1_score_te0 = 0.753968254\n",
      "precision_train1 = 0.756729811 recall_train1 = 0.702127660 f1_score_train1 = 0.728406910\n",
      "precision_te1 = 0.824561404 recall_te1 = 0.758064516 f1_score_te1 = 0.789915966\n",
      "precision_train2 = 0.741324921 recall_train2 = 0.738993711 f1_score_train2 = 0.740157480\n",
      "precision_te2 = 0.720000000 recall_te2 = 0.734693878 f1_score_te2 = 0.727272727\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer foie somewher liter eggplant piquant pud color duck freshli deep ac guy eastern stew wrong miss mussel highli sour model intim pull market amus purpl mismatch would perfect seat assort exquisit smile king chorizo empti stuff green hood favourit substitut octopu upon smell cuba lime disappoint rendit plate\n",
      "market even said behind miss chicken gigant ask friend watch peopl fav form white somewher cod onto sea strawberri bottl might overal love french neighborhood spice filet particular cuba ether substitut line linen candi phone quit amus heart freshli exquisit vegetarian game arugula peach charm flight incompet daili job terribl\n",
      "pick take cool despit suck seafood octopu eastern bass see travel impecc deep loung couldnt asian milkshak second piquant satay desir mac food purpl amount babi pass silverwar eggplant abund print known choos ac heart lo mismatch complaint subway tangi nquett extra item men sweet sure block daili ambianc movi\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  2.7925197747239114e+25\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 30, loss=197.1842041015625, accuracy_train=0.7302100161550888, accuracy_test=0.7412790697674418\n",
      "precision_train0 = 0.707381371 recall_train0 = 0.759433962 f1_score_train0 = 0.732484076\n",
      "precision_te0 = 0.728682171 recall_te0 = 0.770491803 f1_score_te0 = 0.749003984\n",
      "precision_train1 = 0.775862069 recall_train1 = 0.666049954 f1_score_train1 = 0.716774515\n",
      "precision_te1 = 0.828571429 recall_te1 = 0.701612903 f1_score_te1 = 0.759825328\n",
      "precision_train2 = 0.714285714 recall_train2 = 0.770440252 f1_score_train2 = 0.741301059\n",
      "precision_te2 = 0.672727273 recall_te2 = 0.755102041 f1_score_te2 = 0.711538462\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter foie duck eggplant somewher piquant pud freshli stew deep color mussel sour eastern miss guy wrong ac highli pull green perfect market octopu amus purpl assort model would mismatch intim substitut king seat chorizo exquisit stuff juggl onto crab empti smile entre rendit favourit smell tart disappoint\n",
      "even said market behind ask miss friend gigant peopl chicken watch somewher bottl fav form white might overal onto cod love strawberri sea filet french neighborhood substitut cuba particular linen spice phone exquisit freshli ether amus heart quit job candi charm flight seat terribl n line peach perfect eat vegetarian\n",
      "pick cool take despit eastern suck seafood loung deep impecc desir travel asian see second octopu piquant bass couldnt milkshak mac satay print amount purpl nquett silverwar ac pass abund eggplant mismatch choos food heart lo subway complaint item movi sea known sure chandeli fav substitut interior daili extra block\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  2.63139199022844e+25\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 35, loss=196.37154733758223, accuracy_train=0.74281098546042, accuracy_test=0.7558139534883721\n",
      "precision_train0 = 0.736988848 recall_train0 = 0.748113208 f1_score_train0 = 0.742509363\n",
      "precision_te0 = 0.752066116 recall_te0 = 0.745901639 f1_score_te0 = 0.748971193\n",
      "precision_train1 = 0.757925072 recall_train1 = 0.729879741 f1_score_train1 = 0.743638077\n",
      "precision_te1 = 0.811965812 recall_te1 = 0.766129032 f1_score_te1 = 0.788381743\n",
      "precision_train2 = 0.733128834 recall_train2 = 0.751572327 f1_score_train2 = 0.742236025\n",
      "precision_te2 = 0.698113208 recall_te2 = 0.755102041 f1_score_te2 = 0.725490196\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck eggplant foie piquant stew pud somewher sour mussel deep freshli green juggl octopu eastern miss perfect color guy pull assort highli z entre wrong market ac amus substitut zimbabw crab would purpl chorizo king stuff bread model mismatch seat starter rendit intim exquisit tart onto item\n",
      "even said ask behind market friend miss peopl bottl somewher watch gigant chicken might fav overal onto form substitut waiter love n white strawberri filet seat cuba particular linen exquisit cod neighborhood freshli sea french phone job heart charm amus alon terribl flight say eat spice coffe run quit ether\n",
      "pick cool loung despit deep eastern take suck asian seafood travel desir see impecc nquett piquant print second mac couldnt ac purpl mismatch milkshak bass octopu satay chandeli silverwar abund amount pass eggplant heart choos subway movi lo fav substitut interior sure sea complaint tablecloth item exot esqu feel men\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  2.0654693393380747e+25\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 40, loss=195.14893092105262, accuracy_train=0.7492730210016155, accuracy_test=0.75\n",
      "precision_train0 = 0.738970588 recall_train0 = 0.758490566 f1_score_train0 = 0.748603352\n",
      "precision_te0 = 0.747967480 recall_te0 = 0.754098361 f1_score_te0 = 0.751020408\n",
      "precision_train1 = 0.775793651 recall_train1 = 0.723404255 f1_score_train1 = 0.748683581\n",
      "precision_te1 = 0.821428571 recall_te1 = 0.741935484 f1_score_te1 = 0.779661017\n",
      "precision_train2 = 0.733733734 recall_train2 = 0.768343816 f1_score_train2 = 0.750640041\n",
      "precision_te2 = 0.678899083 recall_te2 = 0.755102041 f1_score_te2 = 0.714975845\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck foie eggplant stew juggl piquant green mussel sour octopu z pud deep zimbabw perfect freshli entre miss somewher eastern pull crab assort bread substitut highli short chorizo market guy amus would starter sumatra tart purpl king color item wrong sweet java ac stuff rendit spinach onto\n",
      "even said ask behind market peopl friend waiter bottl miss somewher n watch might seat overal substitut gigant onto form exquisit fav chicken say particular cuba filet love linen freshli job strawberri phone neighborhood alon heart sea terribl eat run white coffe cod charm great amus flight french suck think\n",
      "cool loung pick despit deep eastern nquett asian travel suck see desir chandeli take print mismatch seafood impecc purpl ac couldnt piquant abund second mac milkshak silverwar decor feel satay eggplant pass subway tablecloth bass movi heart octopu market exot choos sure fav bar butter interior amount substitut mood light\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  1.5235764045153758e+25\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 45, loss=193.7254728618421, accuracy_train=0.7541195476575121, accuracy_test=0.7645348837209303\n",
      "precision_train0 = 0.744485294 recall_train0 = 0.764150943 f1_score_train0 = 0.754189944\n",
      "precision_te0 = 0.762295082 recall_te0 = 0.762295082 f1_score_te0 = 0.762295082\n",
      "precision_train1 = 0.781404550 recall_train1 = 0.730804810 f1_score_train1 = 0.755258126\n",
      "precision_te1 = 0.842105263 recall_te1 = 0.774193548 f1_score_te1 = 0.806722689\n",
      "precision_train2 = 0.736947791 recall_train2 = 0.769392034 f1_score_train2 = 0.752820513\n",
      "precision_te2 = 0.685185185 recall_te2 = 0.755102041 f1_score_te2 = 0.718446602\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck juggl green stew foie z eggplant zimbabw mussel piquant octopu sour deep entre perfect pud bread crab short freshli miss sweet pull eastern assort sumatra java starter somewher chorizo substitut tart market spinach highli order item guy amus would king rendit purpl bass stuff monkfish ac\n",
      "even ask said waiter behind peopl n bottl market friend somewher miss seat might watch substitut say friendli overal onto exquisit gigant job particular terribl alon phone great coffe form cuba freshli filet fav eat linen neighborhood love run amus think heart suck strawberri flight sea glass chicken take cod\n",
      "loung cool pick nquett deep decor despit chandeli asian eastern travel see desir feel print mismatch purpl suck bar abund ac light impecc seafood take couldnt piquant tablecloth wall silverwar milkshak mac subway second market exot pass butter movi jazz spot mood eggplant heart satay interior choos sure substitut men\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  1.0079750531501379e+25\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch 50, loss=192.83740619860197, accuracy_train=0.7651050080775444, accuracy_test=0.7674418604651163\n",
      "precision_train0 = 0.769377990 recall_train0 = 0.758490566 f1_score_train0 = 0.763895487\n",
      "precision_te0 = 0.784482759 recall_te0 = 0.745901639 f1_score_te0 = 0.764705882\n",
      "precision_train1 = 0.785440613 recall_train1 = 0.758556892 f1_score_train1 = 0.771764706\n",
      "precision_te1 = 0.819672131 recall_te1 = 0.806451613 f1_score_te1 = 0.813008130\n",
      "precision_train2 = 0.739562624 recall_train2 = 0.779874214 f1_score_train2 = 0.759183673\n",
      "precision_te2 = 0.688679245 recall_te2 = 0.744897959 f1_score_te2 = 0.715686275\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck juggl green z zimbabw stew eggplant foie mussel octopu entre piquant perfect sour short sweet bread deep crab pud sumatra java order starter freshli pull eastern miss spinach assort tart food chorizo market substitut item highli bass somewher slice adult shrimp king amus satay monkfish guy\n",
      "even ask waiter said n peopl bottl behind somewher seat friend market friendli miss say might watch substitut terribl exquisit great overal job coffe onto particular alon phone gigant take eat think suck freshli glass neighborhood run linen amus cuba fav flight filet heart form apolog strawberri love howev incompet\n",
      "loung cool decor nquett pick chandeli deep feel bar light asian despit wall eastern see print mismatch travel desir purpl ac tablecloth abund suck window impecc seafood milkshak spot jazz silverwar mood subway piquant music couldnt market exot butter movi heart second men pass exquisit take mac seat substitut interior\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  8.219800953966505e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 55, loss=192.4726434004934, accuracy_train=0.7731825525040388, accuracy_test=0.7761627906976745\n",
      "precision_train0 = 0.781553398 recall_train0 = 0.759433962 f1_score_train0 = 0.770334928\n",
      "precision_te0 = 0.807017544 recall_te0 = 0.754098361 f1_score_te0 = 0.779661017\n",
      "precision_train1 = 0.797310279 recall_train1 = 0.767807586 f1_score_train1 = 0.782280867\n",
      "precision_te1 = 0.822580645 recall_te1 = 0.822580645 f1_score_te1 = 0.822580645\n",
      "precision_train2 = 0.740234375 recall_train2 = 0.794549266 f1_score_train2 = 0.766430738\n",
      "precision_te2 = 0.688679245 recall_te2 = 0.744897959 f1_score_te2 = 0.715686275\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck green juggl z zimbabw stew eggplant foie mussel entre octopu sweet short perfect bread piquant order sour sumatra deep crab java starter spinach food pud tart pull eastern miss assort freshli shrimp slice chorizo market adult bass substitut item satay highli sauc monkfish fish somewher sea\n",
      "even waiter ask said n peopl bottl friendli seat behind somewher say friend market might miss watch terribl substitut take great coffe exquisit overal job phone alon glass onto think eat particular apolog suck run freshli neighborhood gigant amus flight linen fav cuba filet heart strawberri got refus chang incompet\n",
      "decor loung cool nquett light chandeli feel wall bar deep pick asian despit window print mismatch see tablecloth eastern music desir travel ac purpl spot jazz abund milkshak mood impecc subway suck market silverwar exot piquant seafood movi heart men exquisit couldnt butter interior seat second king pass charm substitut\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  7.405266325922852e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 60, loss=192.29796335320722, accuracy_train=0.7815831987075929, accuracy_test=0.7732558139534884\n",
      "precision_train0 = 0.794921875 recall_train0 = 0.767924528 f1_score_train0 = 0.781190019\n",
      "precision_te0 = 0.815789474 recall_te0 = 0.762295082 f1_score_te0 = 0.788135593\n",
      "precision_train1 = 0.810077519 recall_train1 = 0.773358002 f1_score_train1 = 0.791292002\n",
      "precision_te1 = 0.826446281 recall_te1 = 0.806451613 f1_score_te1 = 0.816326531\n",
      "precision_train2 = 0.740134745 recall_train2 = 0.806079665 f1_score_train2 = 0.771700953\n",
      "precision_te2 = 0.669724771 recall_te2 = 0.744897959 f1_score_te2 = 0.705314010\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck green juggl z zimbabw stew sweet eggplant entre order short foie mussel octopu bread perfect food piquant starter sumatra spinach java crab sour deep tart shrimp pud slice adult pull eastern sauc assort miss bass freshli market chorizo fish item tomato substitut sea satay monkfish mac\n",
      "even waiter ask said n friendli peopl bottl seat say behind somewher take friend might market terribl miss substitut great watch coffe glass apolog job phone exquisit alon eat suck overal think onto particular run refus neighborhood freshli flight got amus gigant manag chang complaint linen strawberri german filet fav\n",
      "decor loung cool light nquett wall chandeli bar feel deep window music pick asian print despit mismatch tablecloth spot jazz ac travel see eastern milkshak desir purpl abund mood scene subway market exot exquisit impecc color heart men modern interior movi rose seat silverwar piquant suck charm king seriou ambianc\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  7.076149410409221e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 65, loss=192.17216411389802, accuracy_train=0.7848142164781906, accuracy_test=0.7790697674418605\n",
      "precision_train0 = 0.801181102 recall_train0 = 0.767924528 f1_score_train0 = 0.784200385\n",
      "precision_te0 = 0.826086957 recall_te0 = 0.778688525 f1_score_te0 = 0.801687764\n",
      "precision_train1 = 0.822200393 recall_train1 = 0.774283071 f1_score_train1 = 0.797522630\n",
      "precision_te1 = 0.833333333 recall_te1 = 0.806451613 f1_score_te1 = 0.819672131\n",
      "precision_train2 = 0.733270500 recall_train2 = 0.815513627 f1_score_train2 = 0.772208437\n",
      "precision_te2 = 0.669724771 recall_te2 = 0.744897959 f1_score_te2 = 0.705314010\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck green juggl z zimbabw sweet order stew eggplant short entre foie mussel octopu food bread perfect starter spinach piquant java sumatra crab shrimp sour tart sauc slice deep adult pud fish pull bass tomato eastern assort market sea miss chorizo freshli satay item monkfish white mac\n",
      "even waiter ask n said friendli peopl bottl seat say take behind somewher terribl might friend apolog great market substitut glass miss coffe watch suck phone job alon think eat exquisit refus manag run particular got overal onto chang complaint flight neighborhood amus freshli german gigant later linen incompet strawberri\n",
      "decor loung cool light wall nquett feel chandeli bar window deep music spot tablecloth asian print pick scene mismatch despit jazz color ac travel milkshak mood see modern eastern desir abund purpl subway exot interior exquisit market rose men seat heart movi impecc king charm ambianc seriou silverwar piquant butter\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  6.874335241014112e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 70, loss=192.04495528371712, accuracy_train=0.7928917609046849, accuracy_test=0.7848837209302325\n",
      "precision_train0 = 0.817097416 recall_train0 = 0.775471698 f1_score_train0 = 0.795740561\n",
      "precision_te0 = 0.833333333 recall_te0 = 0.778688525 f1_score_te0 = 0.805084746\n",
      "precision_train1 = 0.823929961 recall_train1 = 0.783533765 f1_score_train1 = 0.803224277\n",
      "precision_te1 = 0.836065574 recall_te1 = 0.822580645 f1_score_te1 = 0.829268293\n",
      "precision_train2 = 0.739868049 recall_train2 = 0.822851153 f1_score_train2 = 0.779156328\n",
      "precision_te2 = 0.675925926 recall_te2 = 0.744897959 f1_score_te2 = 0.708737864\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck green juggl z zimbabw sweet order stew short food entre eggplant octopu mussel foie bread starter spinach perfect shrimp sauc java sumatra piquant crab slice sour tart adult tomato fish deep bass pud pull sea assort eastern market white chorizo satay freshli mac miss monkfish line\n",
      "even waiter ask n said friendli peopl seat bottl say take somewher behind terribl apolog might glass great substitut friend market coffe watch suck miss phone refus manag job think alon got eat run exquisit particular complaint chang onto later overal neighborhood hour bill flight amus german import incompet freshli\n",
      "decor loung light cool wall feel nquett chandeli bar window music deep scene spot tablecloth asian color print jazz mismatch pick modern despit mood travel ac milkshak see desir eastern abund interior exot subway purpl rose market king exquisit movi seat men charm ambianc seriou gray heart impecc expos stain\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  6.669838015966467e+24\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch 75, loss=191.92155504728618, accuracy_train=0.7983844911147011, accuracy_test=0.7906976744186046\n",
      "precision_train0 = 0.824701195 recall_train0 = 0.781132075 f1_score_train0 = 0.802325581\n",
      "precision_te0 = 0.855855856 recall_te0 = 0.778688525 f1_score_te0 = 0.815450644\n",
      "precision_train1 = 0.825750242 recall_train1 = 0.789084181 f1_score_train1 = 0.807000946\n",
      "precision_te1 = 0.830645161 recall_te1 = 0.830645161 f1_score_te1 = 0.830645161\n",
      "precision_train2 = 0.746691871 recall_train2 = 0.828092243 f1_score_train2 = 0.785288270\n",
      "precision_te2 = 0.678899083 recall_te2 = 0.755102041 f1_score_te2 = 0.714975845\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck green juggl z zimbabw order sweet stew food short entre octopu mussel eggplant foie starter bread spinach sauc shrimp perfect java slice sumatra crab piquant tart tomato adult sour fish bass deep sea pud pull assort white eastern mac line satay pea market monkfish chorizo freshli\n",
      "even waiter ask n said friendli seat peopl take bottl say terribl apolog somewher behind glass might great substitut coffe market friend manag suck refus phone miss watch think got run job alon hour eat exquisit particular bill complaint chang later rude onto neighborhood import german list member p mention\n",
      "decor light loung wall cool feel nquett chandeli bar window music scene spot deep color tablecloth asian print modern jazz mismatch mood pick milkshak travel ac see despit interior desir eastern abund exot rose subway king gray movi men market purpl charm expos exquisit seat eleg ambianc seriou stain heart\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  6.49433305338663e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 80, loss=191.8330052425987, accuracy_train=0.8054927302100161, accuracy_test=0.7965116279069767\n",
      "precision_train0 = 0.834331337 recall_train0 = 0.788679245 f1_score_train0 = 0.810863240\n",
      "precision_te0 = 0.864864865 recall_te0 = 0.786885246 f1_score_te0 = 0.824034335\n",
      "precision_train1 = 0.838423645 recall_train1 = 0.787234043 f1_score_train1 = 0.812022901\n",
      "precision_te1 = 0.832000000 recall_te1 = 0.838709677 f1_score_te1 = 0.835341365\n",
      "precision_train2 = 0.747680891 recall_train2 = 0.844863732 f1_score_train2 = 0.793307087\n",
      "precision_te2 = 0.685185185 recall_te2 = 0.755102041 f1_score_te2 = 0.718446602\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck green order juggl z zimbabw sweet food stew short octopu mussel entre sauc starter shrimp bread eggplant spinach foie slice perfect java tomato sumatra tart crab adult piquant fish sour bass sea deep pud pull white assort line mac satay pea eastern chorizo monkfish market dri\n",
      "even waiter ask n said friendli seat peopl take say bottl apolog terribl somewher behind glass might great manag substitut coffe refus suck market phone hour friend think got run bill miss watch job alon exquisit particular rude complaint eat later chang us member mention list help import p never\n",
      "decor light loung wall cool feel nquett window chandeli music bar scene color spot tablecloth deep modern asian print jazz mismatch mood milkshak see interior travel ac eastern pick exot rose gray desir despit abund movi expos charm eleg king men subway purpl seriou market stain seat exquisit ambianc heart\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  6.310994634742584e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 85, loss=191.75551372327303, accuracy_train=0.8103392568659128, accuracy_test=0.8023255813953488\n",
      "precision_train0 = 0.837117473 recall_train0 = 0.800000000 f1_score_train0 = 0.818137964\n",
      "precision_te0 = 0.866071429 recall_te0 = 0.795081967 f1_score_te0 = 0.829059829\n",
      "precision_train1 = 0.844400396 recall_train1 = 0.788159112 f1_score_train1 = 0.815311005\n",
      "precision_te1 = 0.833333333 recall_te1 = 0.846774194 f1_score_te1 = 0.840000000\n",
      "precision_train2 = 0.753028891 recall_train2 = 0.846960168 f1_score_train2 = 0.797237296\n",
      "precision_te2 = 0.698113208 recall_te2 = 0.755102041 f1_score_te2 = 0.725490196\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck green order sweet juggl z zimbabw food stew short sauc mussel octopu shrimp starter entre bread spinach eggplant foie slice tomato tart java crab perfect sumatra adult fish piquant sour sea bass deep pud white pull line mac assort satay pea chorizo dri monkfish eastern market\n",
      "even waiter n ask said friendli seat take peopl say bottl apolog terribl glass somewher manag behind great hour substitut might refus coffe suck phone bill think market got friend run rude us job complaint exquisit watch particular later miss alon help eat chang never member p list mention import\n",
      "decor light loung wall cool feel window nquett scene color chandeli music bar spot tablecloth deep modern asian print jazz mismatch mood interior see milkshak expos gray eleg travel movi charm rose exot eastern desir ac king stain pick men despit seriou abund subway purpl heart market somewher upstair kitchen\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  6.177407464214436e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 90, loss=191.66533717105264, accuracy_train=0.8113085621970921, accuracy_test=0.8023255813953488\n",
      "precision_train0 = 0.842000000 recall_train0 = 0.794339623 f1_score_train0 = 0.817475728\n",
      "precision_te0 = 0.866071429 recall_te0 = 0.795081967 f1_score_te0 = 0.829059829\n",
      "precision_train1 = 0.849056604 recall_train1 = 0.790934320 f1_score_train1 = 0.818965517\n",
      "precision_te1 = 0.840000000 recall_te1 = 0.846774194 f1_score_te1 = 0.843373494\n",
      "precision_train2 = 0.748161765 recall_train2 = 0.853249476 f1_score_train2 = 0.797257591\n",
      "precision_te2 = 0.691588785 recall_te2 = 0.755102041 f1_score_te2 = 0.721951220\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck green order sweet zimbabw z juggl food stew short sauc shrimp octopu starter mussel spinach bread entre eggplant slice tomato foie tart crab fish java adult sumatra perfect sea sour piquant bass pud deep white line pull mac pea satay assort dri chorizo corn market monkfish\n",
      "even waiter n ask said friendli seat take peopl say bottl apolog terribl glass manag somewher hour great behind refus substitut bill suck might phone us coffe think got rude market help run friend complaint later never job exquisit particular alon chang watch eat miss list member mention p import\n",
      "decor light loung wall cool color window feel nquett scene music chandeli bar spot tablecloth deep modern asian jazz print mismatch mood expos interior eleg see gray charm milkshak movi rose stain exot eastern travel king seriou desir heart ac men somewher subway pick upstair despit market altern abund kitchen\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  6.064025509808721e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 95, loss=191.58008326480262, accuracy_train=0.81421647819063, accuracy_test=0.8081395348837209\n",
      "precision_train0 = 0.847152847 recall_train0 = 0.800000000 f1_score_train0 = 0.822901504\n",
      "precision_te0 = 0.867256637 recall_te0 = 0.803278689 f1_score_te0 = 0.834042553\n",
      "precision_train1 = 0.851445663 recall_train1 = 0.790009251 f1_score_train1 = 0.819577735\n",
      "precision_te1 = 0.841269841 recall_te1 = 0.854838710 f1_score_te1 = 0.848000000\n",
      "precision_train2 = 0.749770852 recall_train2 = 0.857442348 f1_score_train2 = 0.800000000\n",
      "precision_te2 = 0.704761905 recall_te2 = 0.755102041 f1_score_te2 = 0.729064039\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck green order sweet zimbabw z juggl food stew short sauc starter shrimp octopu eggplant slice mussel tomato spinach bread entre foie tart fish crab adult java sea sumatra perfect sour piquant bass pud line white deep mac pea pull satay assort dri corn chorizo saute market\n",
      "even waiter n ask said friendli seat take peopl say bottl apolog terribl glass manag hour somewher us bill refus substitut great behind suck phone think coffe rude might got help never later run complaint market job exquisit particular friend list eat chang alon mention lose p import member miss\n",
      "decor light loung color wall cool window scene nquett feel music chandeli spot bar tablecloth modern deep jazz asian print mismatch mood expos eleg interior gray see stain charm movi rose milkshak exot eastern seriou king heart travel men desir somewher ba ac upstair kitchen altern subway market ambianc rustic\n",
      "---------------End of Topics------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximated perplexity is:  5.884904396996235e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 100, loss=191.53256450452304, accuracy_train=0.8222940226171244, accuracy_test=0.811046511627907\n",
      "precision_train0 = 0.855566700 recall_train0 = 0.804716981 f1_score_train0 = 0.829363150\n",
      "precision_te0 = 0.868421053 recall_te0 = 0.811475410 f1_score_te0 = 0.838983051\n",
      "precision_train1 = 0.848162476 recall_train1 = 0.811285846 f1_score_train1 = 0.829314421\n",
      "precision_te1 = 0.834645669 recall_te1 = 0.854838710 f1_score_te1 = 0.844621514\n",
      "precision_train2 = 0.765977444 recall_train2 = 0.854297694 f1_score_train2 = 0.807730426\n",
      "precision_te2 = 0.718446602 recall_te2 = 0.755102041 f1_score_te2 = 0.736318408\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer liter duck green sweet order zimbabw z juggl food stew short sauc starter octopu shrimp slice eggplant tomato mussel spinach entre bread foie tart fish sea crab adult java sumatra perfect bass sour piquant line white pud mac deep pea satay pull corn assort chorizo dri saute horseradish\n",
      "even waiter n ask said friendli seat take peopl say bottl apolog terribl glass hour manag us bill refus somewher substitut phone great suck behind think never rude help coffe got later might complaint run job particular exquisit list host market friend p mention lose though eat amount attitud chang\n",
      "decor light loung color window cool wall nquett scene feel music chandeli spot bar tablecloth modern deep jazz asian print mismatch expos eleg interior mood gray movi stain charm see rose seriou exot milkshak ba men somewher heart king eastern upstair travel kitchen desir ambianc behind altern rustic subway abund\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  5.734381328888858e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 105, loss=191.41814093338814, accuracy_train=0.8248788368336026, accuracy_test=0.8081395348837209\n",
      "precision_train0 = 0.863360324 recall_train0 = 0.804716981 f1_score_train0 = 0.833007812\n",
      "precision_te0 = 0.868421053 recall_te0 = 0.811475410 f1_score_te0 = 0.838983051\n",
      "precision_train1 = 0.852570320 recall_train1 = 0.813135985 f1_score_train1 = 0.832386364\n",
      "precision_te1 = 0.833333333 recall_te1 = 0.846774194 f1_score_te1 = 0.840000000\n",
      "precision_train2 = 0.763011152 recall_train2 = 0.860587002 f1_score_train2 = 0.808866995\n",
      "precision_te2 = 0.711538462 recall_te2 = 0.755102041 f1_score_te2 = 0.732673267\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck liter sweet order zimbabw z food juggl stew short sauc starter octopu slice shrimp tomato eggplant spinach mussel foie sea entre bread fish tart crab adult java sumatra perfect bass sour piquant line mac pea pud deep white satay pull corn horseradish assort arugula saute chorizo\n",
      "even waiter n ask said friendli seat take peopl say bottl apolog terribl hour glass manag us bill refus somewher substitut never phone great suck rude think help behind got coffe later complaint run though might host exquisit lose p particular attitud job min mention list amount parti eat colleg\n",
      "decor light color loung window nquett cool scene wall music feel chandeli spot bar tablecloth modern deep jazz asian expos print mismatch interior eleg gray mood stain movi rose charm ba see seriou men somewher exot king upstair milkshak heart behind ambianc eastern rustic travel intim fireplac kitchen desir altern\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  5.655939913685303e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 110, loss=191.3987767269737, accuracy_train=0.8294022617124395, accuracy_test=0.8168604651162791\n",
      "precision_train0 = 0.871165644 recall_train0 = 0.803773585 f1_score_train0 = 0.836113837\n",
      "precision_te0 = 0.884955752 recall_te0 = 0.819672131 f1_score_te0 = 0.851063830\n",
      "precision_train1 = 0.848484848 recall_train1 = 0.828862165 f1_score_train1 = 0.838558727\n",
      "precision_te1 = 0.841269841 recall_te1 = 0.854838710 f1_score_te1 = 0.848000000\n",
      "precision_train2 = 0.771913289 recall_train2 = 0.858490566 f1_score_train2 = 0.812903226\n",
      "precision_te2 = 0.714285714 recall_te2 = 0.765306122 f1_score_te2 = 0.738916256\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck liter sweet order food zimbabw z juggl stew short sauc starter octopu slice shrimp tomato eggplant spinach mussel sea foie fish tart bread entre adult crab java sumatra bass perfect sour piquant line mac pea pud deep white satay pull arugula like corn assort cod saute\n",
      "even waiter n said friendli seat ask take peopl say bottl apolog terribl hour glass manag us bill refus never phone substitut somewher rude help great think suck got later behind coffe complaint though run host min lose mention attitud parti p particular exquisit amount might colleg job list complain\n",
      "decor light color loung nquett window cool scene music wall feel spot chandeli tablecloth bar modern deep jazz asian expos mismatch interior print gray eleg mood stain movi ba charm rose see somewher men seriou behind intim king exot upstair rustic fireplac heart travel milkshak ambianc eastern altern desir kitchen\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  5.5658549607179e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 115, loss=191.3015779194079, accuracy_train=0.8319870759289176, accuracy_test=0.8226744186046512\n",
      "precision_train0 = 0.875642343 recall_train0 = 0.803773585 f1_score_train0 = 0.838170192\n",
      "precision_te0 = 0.893805310 recall_te0 = 0.827868852 f1_score_te0 = 0.859574468\n",
      "precision_train1 = 0.850000000 recall_train1 = 0.833487512 f1_score_train1 = 0.841662774\n",
      "precision_te1 = 0.841269841 recall_te1 = 0.854838710 f1_score_te1 = 0.848000000\n",
      "precision_train2 = 0.774011299 recall_train2 = 0.861635220 f1_score_train2 = 0.815476190\n",
      "precision_te2 = 0.723809524 recall_te2 = 0.775510204 f1_score_te2 = 0.748768473\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck liter sweet order food zimbabw stew z juggl starter sauc octopu short slice shrimp tomato eggplant spinach sea foie mussel fish tart bread entre adult crab bass java sumatra perfect sour piquant line mac pea deep pud satay like cod arugula white saute corn assort pull\n",
      "even waiter n seat said friendli take ask peopl say bottl apolog terribl hour glass us manag bill refus never phone substitut help rude somewher think later suck great got though coffe behind complaint host min run lose mention parti attitud amount colleg p particular exquisit complain member job import\n",
      "decor color light loung nquett window cool scene music spot feel wall chandeli tablecloth bar modern jazz deep asian expos interior mismatch gray eleg print stain mood ba movi rose charm intim behind somewher men king rustic fireplac seriou upstair exot see sleek spaciou subway heart patron altern ambianc wood\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  5.432509692633136e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 120, loss=191.23192331414472, accuracy_train=0.8348949919224555, accuracy_test=0.8255813953488372\n",
      "precision_train0 = 0.881075491 recall_train0 = 0.803773585 f1_score_train0 = 0.840651209\n",
      "precision_te0 = 0.901785714 recall_te0 = 0.827868852 f1_score_te0 = 0.863247863\n",
      "precision_train1 = 0.849250936 recall_train1 = 0.839037928 f1_score_train1 = 0.844113541\n",
      "precision_te1 = 0.841269841 recall_te1 = 0.854838710 f1_score_te1 = 0.848000000\n",
      "precision_train2 = 0.778301887 recall_train2 = 0.864779874 f1_score_train2 = 0.819265144\n",
      "precision_te2 = 0.726415094 recall_te2 = 0.785714286 f1_score_te2 = 0.754901961\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck liter sweet food order stew zimbabw z juggl starter octopu sauc slice short shrimp tomato sea eggplant spinach foie mussel fish tart bread adult crab entre bass java sumatra perfect sour piquant line mac deep pud pea satay like cod arugula saute corn chorizo horseradish assort\n",
      "even waiter n seat said friendli take ask peopl say bottl apolog terribl hour us glass bill manag refus never phone help substitut rude think somewher later though got suck great coffe behind complaint host min lose mention attitud amount parti run colleg p particular complain smile exquisit member import\n",
      "decor color light loung nquett window cool scene music spot feel chandeli wall tablecloth modern bar jazz deep asian expos interior mismatch gray eleg stain print ba mood intim rose movi charm behind fireplac rustic men upstair somewher king spaciou sleek exot subway patron seriou see desir wood heart altern\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  5.405421242200331e+24\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch 125, loss=191.1849789268092, accuracy_train=0.8358642972536349, accuracy_test=0.8284883720930233\n",
      "precision_train0 = 0.882109617 recall_train0 = 0.804716981 f1_score_train0 = 0.841637889\n",
      "precision_te0 = 0.902654867 recall_te0 = 0.836065574 f1_score_te0 = 0.868085106\n",
      "precision_train1 = 0.843663275 recall_train1 = 0.843663275 f1_score_train1 = 0.843663275\n",
      "precision_te1 = 0.848000000 recall_te1 = 0.854838710 f1_score_te1 = 0.851405622\n",
      "precision_train2 = 0.785100287 recall_train2 = 0.861635220 f1_score_train2 = 0.821589205\n",
      "precision_te2 = 0.726415094 recall_te2 = 0.785714286 f1_score_te2 = 0.754901961\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck liter sweet stew food zimbabw z juggl order starter octopu slice sauc short shrimp tomato sea eggplant spinach foie mussel tart fish bread adult crab bass entre java sumatra piquant sour perfect line mac pud deep pea like cod satay saute arugula corn delic chorizo horseradish\n",
      "even waiter n seat take said friendli ask peopl say bottl apolog terribl hour us glass bill manag never refus help phone rude later substitut though somewher think got suck host great coffe complaint min behind mention amount attitud lose colleg parti run complain p smile particular member import exquisit\n",
      "decor color light loung window nquett cool scene music chandeli spot feel wall tablecloth modern bar jazz deep asian expos interior mismatch gray eleg stain ba intim print rose mood movi charm fireplac rustic behind upstair spaciou men somewher king patron sleek subway exot gigant area wood desir heart seriou\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  5.287179744443869e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 130, loss=191.1378148129112, accuracy_train=0.8374798061389338, accuracy_test=0.8255813953488372\n",
      "precision_train0 = 0.886221294 recall_train0 = 0.800943396 f1_score_train0 = 0.841427156\n",
      "precision_te0 = 0.901785714 recall_te0 = 0.827868852 f1_score_te0 = 0.863247863\n",
      "precision_train1 = 0.839122486 recall_train1 = 0.849213691 f1_score_train1 = 0.844137931\n",
      "precision_te1 = 0.841269841 recall_te1 = 0.854838710 f1_score_te1 = 0.848000000\n",
      "precision_train2 = 0.790987536 recall_train2 = 0.864779874 f1_score_train2 = 0.826239359\n",
      "precision_te2 = 0.726415094 recall_te2 = 0.785714286 f1_score_te2 = 0.754901961\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck liter sweet stew zimbabw food z juggl order starter octopu slice sea sauc tomato shrimp short eggplant spinach foie mussel tart fish adult bread bass crab java sumatra entre piquant sour mac perfect line pud cod deep like pea satay saute corn delic arugula chorizo dri\n",
      "even waiter n seat take said friendli peopl ask say bottl apolog hour terribl us glass bill never manag refus help later phone rude substitut though somewher think got suck host min complaint coffe behind great mention attitud colleg lose amount parti smile p complain run particular member decid much\n",
      "decor color light loung window nquett cool music scene chandeli spot feel wall tablecloth modern bar jazz deep expos asian interior gray mismatch eleg intim stain ba rose print mood charm movi rustic spaciou fireplac upstair behind men patron somewher area sleek exot king gigant dim subway crowd wood desir\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  5.196105310892188e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 135, loss=191.09683645148027, accuracy_train=0.8397415185783522, accuracy_test=0.8284883720930233\n",
      "precision_train0 = 0.889352818 recall_train0 = 0.803773585 f1_score_train0 = 0.844400396\n",
      "precision_te0 = 0.909909910 recall_te0 = 0.827868852 f1_score_te0 = 0.866952790\n",
      "precision_train1 = 0.842346471 recall_train1 = 0.850138760 f1_score_train1 = 0.846224678\n",
      "precision_te1 = 0.841269841 recall_te1 = 0.854838710 f1_score_te1 = 0.848000000\n",
      "precision_train2 = 0.791586998 recall_train2 = 0.867924528 f1_score_train2 = 0.828000000\n",
      "precision_te2 = 0.728971963 recall_te2 = 0.795918367 f1_score_te2 = 0.760975610\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck liter sweet stew zimbabw z juggl food starter octopu sea slice tomato sauc shrimp order short eggplant mussel spinach foie tart fish adult bass bread crab java sumatra entre piquant sour mac cod pud line perfect like pea deep satay saute delic corn arugula chorizo dri\n",
      "even waiter n seat take said friendli peopl ask say bottl apolog hour terribl never bill glass us manag refus help later phone rude though substitut think somewher suck min got coffe host complaint behind colleg attitud amount lose mention great smile p complain parti member run particular decid much\n",
      "decor color light loung window nquett music cool scene chandeli spot feel tablecloth wall modern bar jazz deep expos asian interior gray eleg intim mismatch ba stain rose rustic print spaciou movi mood upstair charm fireplac area behind patron men sleek somewher dim exot gigant crowd king subway wood view\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  5.127700244436067e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 140, loss=191.0484709087171, accuracy_train=0.8407108239095316, accuracy_test=0.8255813953488372\n",
      "precision_train0 = 0.895348837 recall_train0 = 0.799056604 f1_score_train0 = 0.844466600\n",
      "precision_te0 = 0.909090909 recall_te0 = 0.819672131 f1_score_te0 = 0.862068966\n",
      "precision_train1 = 0.837691614 recall_train1 = 0.859389454 f1_score_train1 = 0.848401826\n",
      "precision_te1 = 0.834645669 recall_te1 = 0.854838710 f1_score_te1 = 0.844621514\n",
      "precision_train2 = 0.794230769 recall_train2 = 0.865828092 f1_score_train2 = 0.828485456\n",
      "precision_te2 = 0.728971963 recall_te2 = 0.795918367 f1_score_te2 = 0.760975610\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet liter stew zimbabw z juggl food sea starter octopu slice tomato eggplant sauc shrimp mussel short spinach foie tart order fish adult bass bread crab java sumatra piquant cod sour entre mac pud line like pea deep perfect satay saute delic corn arugula chorizo dri\n",
      "even waiter n seat take said friendli peopl ask say apolog bottl hour terribl never bill us glass manag refus later help phone though substitut rude think somewher suck min coffe got colleg host complaint behind lose attitud amount mention smile member great decid complain parti p run particular write\n",
      "decor color light loung nquett window music cool spot chandeli scene feel tablecloth wall modern bar jazz expos asian deep gray interior intim eleg ba mismatch stain rustic rose spaciou print upstair area movi fireplac charm mood behind sleek patron men dim somewher gigant crowd exot subway view king beam\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  5.059021245000753e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 145, loss=191.00531198601973, accuracy_train=0.8403877221324717, accuracy_test=0.8313953488372093\n",
      "precision_train0 = 0.893955461 recall_train0 = 0.795283019 f1_score_train0 = 0.841737394\n",
      "precision_te0 = 0.909909910 recall_te0 = 0.827868852 f1_score_te0 = 0.866952790\n",
      "precision_train1 = 0.832442068 recall_train1 = 0.864014801 f1_score_train1 = 0.847934635\n",
      "precision_te1 = 0.835937500 recall_te1 = 0.862903226 f1_score_te1 = 0.849206349\n",
      "precision_train2 = 0.800000000 recall_train2 = 0.863731656 f1_score_train2 = 0.830645161\n",
      "precision_te2 = 0.742857143 recall_te2 = 0.795918367 f1_score_te2 = 0.768472906\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet liter stew zimbabw z juggl food sea starter octopu slice eggplant tomato shrimp spinach sauc mussel tart short foie fish adult bass order bread crab java sumatra cod piquant sour pud mac line like entre pea deep saute satay delic corn perfect arugula assort chorizo\n",
      "even waiter n seat take said friendli peopl say ask apolog bottl hour terribl never bill us glass manag refus later help phone though substitut rude think somewher suck min colleg lose coffe host complaint amount attitud mention behind got decid member smile parti complain p run particular great spoke\n",
      "decor color loung light nquett window music cool spot chandeli scene feel tablecloth modern wall jazz bar asian expos gray intim deep interior eleg ba stain mismatch rustic rose spaciou upstair area print fireplac movi mood sleek dim charm behind patron men gigant crowd somewher exot view beam subway king\n",
      "---------------End of Topics------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximated perplexity is:  5.003832461750377e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 150, loss=190.93934518914475, accuracy_train=0.8410339256865913, accuracy_test=0.8343023255813954\n",
      "precision_train0 = 0.900534759 recall_train0 = 0.794339623 f1_score_train0 = 0.844110276\n",
      "precision_te0 = 0.909909910 recall_te0 = 0.827868852 f1_score_te0 = 0.866952790\n",
      "precision_train1 = 0.827464789 recall_train1 = 0.869565217 f1_score_train1 = 0.847992783\n",
      "precision_te1 = 0.837209302 recall_te1 = 0.870967742 f1_score_te1 = 0.853754941\n",
      "precision_train2 = 0.801757812 recall_train2 = 0.860587002 f1_score_train2 = 0.830131446\n",
      "precision_te2 = 0.750000000 recall_te2 = 0.795918367 f1_score_te2 = 0.772277228\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet liter stew zimbabw z juggl sea starter food octopu eggplant slice tomato spinach mussel shrimp tart sauc foie short fish bass adult bread crab cod java sumatra sour piquant order pud like mac line pea deep entre saute delic satay corn arugula assort perfect chorizo\n",
      "even waiter n seat take said friendli peopl say ask apolog bottl hour terribl never bill us glass manag refus later help though phone think substitut rude somewher min suck lose complaint colleg host attitud coffe amount mention decid behind complain parti member p got smile spoke particular run write\n",
      "decor color loung nquett window light cool music chandeli spot scene feel tablecloth modern wall jazz bar asian gray expos intim interior deep ba eleg stain mismatch rustic spaciou rose area upstair fireplac print dim movi sleek patron charm mood behind gigant men crowd somewher exot view beam upper accent\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  4.915768112181352e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 155, loss=190.9165681537829, accuracy_train=0.8410339256865913, accuracy_test=0.8343023255813954\n",
      "precision_train0 = 0.904761905 recall_train0 = 0.788679245 f1_score_train0 = 0.842741935\n",
      "precision_te0 = 0.909909910 recall_te0 = 0.827868852 f1_score_te0 = 0.866952790\n",
      "precision_train1 = 0.824146982 recall_train1 = 0.871415356 f1_score_train1 = 0.847122302\n",
      "precision_te1 = 0.837209302 recall_te1 = 0.870967742 f1_score_te1 = 0.853754941\n",
      "precision_train2 = 0.802529183 recall_train2 = 0.864779874 f1_score_train2 = 0.832492432\n",
      "precision_te2 = 0.750000000 recall_te2 = 0.795918367 f1_score_te2 = 0.772277228\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet liter stew zimbabw z juggl sea starter eggplant food octopu slice tomato tart mussel spinach shrimp foie sauc short bass fish adult cod crab bread java sumatra sour piquant pud like pea mac line delic saute deep corn satay entre order arugula assort horseradish chorizo\n",
      "even waiter n seat take said peopl friendli say apolog ask bottl hour terribl never bill us glass refus manag later though help phone think substitut rude somewher min suck lose complaint colleg host attitud decid mention amount coffe spoke p behind parti complain member smile particular got run write\n",
      "decor color loung nquett window light cool chandeli music spot scene tablecloth feel modern wall jazz bar intim gray asian expos interior ba deep eleg stain spaciou area rustic rose mismatch upstair fireplac dim print sleek movi patron charm behind gigant mood men crowd somewher beam view accent exot upper\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  4.86243644629129e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 160, loss=190.88028628700658, accuracy_train=0.8420032310177706, accuracy_test=0.8430232558139535\n",
      "precision_train0 = 0.905537459 recall_train0 = 0.786792453 f1_score_train0 = 0.841998990\n",
      "precision_te0 = 0.918918919 recall_te0 = 0.836065574 f1_score_te0 = 0.875536481\n",
      "precision_train1 = 0.820934256 recall_train1 = 0.877890842 f1_score_train1 = 0.848457756\n",
      "precision_te1 = 0.827067669 recall_te1 = 0.887096774 f1_score_te1 = 0.856031128\n",
      "precision_train2 = 0.808447937 recall_train2 = 0.862683438 f1_score_train2 = 0.834685598\n",
      "precision_te2 = 0.780000000 recall_te2 = 0.795918367 f1_score_te2 = 0.787878788\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet liter stew zimbabw z juggl sea starter eggplant slice octopu food tomato tart mussel spinach shrimp foie sauc bass short adult fish cod crab java bread sumatra sour piquant pud like delic pea line mac saute deep corn satay entre arugula assort horseradish chorizo dri\n",
      "even waiter n seat take said peopl friendli apolog say ask bottl hour terribl never bill glass us refus manag later think though phone help substitut rude somewher min suck lose complaint colleg mention attitud decid host p spoke amount coffe parti complain behind member smile particular got run much\n",
      "decor color loung nquett window light chandeli cool music spot tablecloth scene feel modern wall jazz bar intim gray expos asian interior ba deep eleg spaciou stain area rustic rose dim fireplac upstair mismatch movi sleek patron print gigant behind charm mood men crowd beam accent view somewher upper exot\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  4.845071494447303e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 165, loss=190.85980931332236, accuracy_train=0.8439418416801292, accuracy_test=0.8488372093023255\n",
      "precision_train0 = 0.907908992 recall_train0 = 0.790566038 f1_score_train0 = 0.845184065\n",
      "precision_te0 = 0.919642857 recall_te0 = 0.844262295 f1_score_te0 = 0.880341880\n",
      "precision_train1 = 0.816780822 recall_train1 = 0.882516189 f1_score_train1 = 0.848377056\n",
      "precision_te1 = 0.823529412 recall_te1 = 0.903225806 f1_score_te1 = 0.861538462\n",
      "precision_train2 = 0.816733068 recall_train2 = 0.859538784 f1_score_train2 = 0.837589377\n",
      "precision_te2 = 0.802083333 recall_te2 = 0.785714286 f1_score_te2 = 0.793814433\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet liter stew zimbabw z sea juggl starter eggplant octopu slice tomato tart mussel food foie spinach shrimp sauc bass adult cod fish short crab sour java sumatra bread piquant pud delic pea like mac saute deep line corn satay assort horseradish arugula entre chorizo homemad\n",
      "even waiter n seat take said peopl friendli apolog say ask bottl terribl hour never bill refus glass us manag later think though phone help substitut rude somewher min lose suck complaint spoke colleg decid mention attitud p host amount coffe parti complain smile behind member particular run got much\n",
      "decor color loung nquett window light chandeli cool spot music tablecloth scene feel modern jazz wall intim bar gray expos interior asian ba spaciou eleg deep stain area rustic rose dim fireplac upstair mismatch sleek movi patron behind gigant mood print charm men beam crowd accent view upper somewher franchis\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  4.784116325309034e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 170, loss=190.7639982524671, accuracy_train=0.8426494345718901, accuracy_test=0.8488372093023255\n",
      "precision_train0 = 0.908596300 recall_train0 = 0.787735849 f1_score_train0 = 0.843860536\n",
      "precision_te0 = 0.919642857 recall_te0 = 0.844262295 f1_score_te0 = 0.880341880\n",
      "precision_train1 = 0.816151203 recall_train1 = 0.878815911 f1_score_train1 = 0.846325167\n",
      "precision_te1 = 0.823529412 recall_te1 = 0.903225806 f1_score_te1 = 0.861538462\n",
      "precision_train2 = 0.813241107 recall_train2 = 0.862683438 f1_score_train2 = 0.837232960\n",
      "precision_te2 = 0.802083333 recall_te2 = 0.785714286 f1_score_te2 = 0.793814433\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet liter stew zimbabw sea z juggl starter eggplant octopu slice tart mussel tomato spinach foie food shrimp sauc cod bass adult fish short crab sour java sumatra piquant pud delic bread pea like mac saute deep line corn satay assort horseradish arugula chorizo homemad monkfish\n",
      "even waiter n seat take said peopl apolog friendli say ask bottl terribl hour never bill refus glass us later think manag though phone help substitut rude somewher min lose suck spoke colleg decid complaint mention p attitud host amount complain coffe parti smile behind member particular much run worst\n",
      "decor color loung nquett window chandeli light spot cool music tablecloth scene modern feel jazz wall intim bar gray expos interior asian ba spaciou eleg area stain deep rustic dim rose fireplac upstair mismatch sleek movi gigant patron behind mood print charm men beam accent crowd view leather upper exot\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  4.7546529229212974e+24\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Epoch 175, loss=190.77858115748356, accuracy_train=0.8465266558966075, accuracy_test=0.8459302325581395\n",
      "precision_train0 = 0.914754098 recall_train0 = 0.789622642 f1_score_train0 = 0.847594937\n",
      "precision_te0 = 0.919642857 recall_te0 = 0.844262295 f1_score_te0 = 0.880341880\n",
      "precision_train1 = 0.813717189 recall_train1 = 0.888991674 f1_score_train1 = 0.849690539\n",
      "precision_te1 = 0.817518248 recall_te1 = 0.903225806 f1_score_te1 = 0.858237548\n",
      "precision_train2 = 0.822822823 recall_train2 = 0.861635220 f1_score_train2 = 0.841781874\n",
      "precision_te2 = 0.800000000 recall_te2 = 0.775510204 f1_score_te2 = 0.787564767\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet liter stew sea zimbabw z juggl starter eggplant octopu slice tart mussel spinach tomato foie shrimp food cod bass sauc adult fish sour short crab java piquant delic sumatra pud pea like mac saute deep bread corn line satay assort horseradish arugula chorizo monkfish homemad\n",
      "even waiter n seat take said peopl apolog friendli ask say bottl terribl hour never bill refus glass later think us though phone manag substitut help rude min somewher lose spoke suck colleg decid mention complaint p host attitud complain amount coffe parti behind smile member particular much worst run\n",
      "decor color loung nquett window chandeli spot cool light music tablecloth scene modern feel jazz wall intim gray bar expos interior asian ba spaciou eleg area stain rustic dim deep fireplac upstair rose mismatch gigant movi sleek mood patron behind print beam charm men crowd accent leather view linen upper\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  4.671906945522459e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 180, loss=190.73566509046051, accuracy_train=0.8468497576736672, accuracy_test=0.8459302325581395\n",
      "precision_train0 = 0.913755459 recall_train0 = 0.789622642 f1_score_train0 = 0.847165992\n",
      "precision_te0 = 0.919642857 recall_te0 = 0.844262295 f1_score_te0 = 0.880341880\n",
      "precision_train1 = 0.810084034 recall_train1 = 0.891766883 f1_score_train1 = 0.848965214\n",
      "precision_te1 = 0.817518248 recall_te1 = 0.903225806 f1_score_te1 = 0.858237548\n",
      "precision_train2 = 0.829120324 recall_train2 = 0.859538784 f1_score_train2 = 0.844055584\n",
      "precision_te2 = 0.800000000 recall_te2 = 0.775510204 f1_score_te2 = 0.787564767\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet stew liter sea zimbabw juggl starter z eggplant octopu tart mussel spinach slice foie tomato shrimp cod bass food sauc adult fish sour delic crab piquant java sumatra pud short mac pea saute like deep corn bread assort satay line horseradish arugula chorizo monkfish homemad\n",
      "even waiter n seat take said peopl apolog ask friendli say bottl terribl hour never bill refus glass later think though phone us manag min substitut rude somewher help lose spoke decid mention colleg suck complaint p complain host attitud amount behind coffe smile parti member particular worst much ac\n",
      "decor color loung nquett window chandeli spot cool music light tablecloth modern scene feel jazz intim wall gray bar expos interior ba asian spaciou eleg area stain rustic dim fireplac upstair deep rose mismatch gigant sleek movi mood patron beam print crowd behind charm leather men accent linen view upper\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  4.6367332875245015e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 185, loss=190.72629009046054, accuracy_train=0.848465266558966, accuracy_test=0.8488372093023255\n",
      "precision_train0 = 0.914940022 recall_train0 = 0.791509434 f1_score_train0 = 0.848760749\n",
      "precision_te0 = 0.919642857 recall_te0 = 0.844262295 f1_score_te0 = 0.880341880\n",
      "precision_train1 = 0.809723386 recall_train1 = 0.893617021 f1_score_train1 = 0.849604222\n",
      "precision_te1 = 0.818840580 recall_te1 = 0.911290323 f1_score_te1 = 0.862595420\n",
      "precision_train2 = 0.833502538 recall_train2 = 0.860587002 f1_score_train2 = 0.846828262\n",
      "precision_te2 = 0.808510638 recall_te2 = 0.775510204 f1_score_te2 = 0.791666667\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet stew liter sea zimbabw starter juggl z eggplant tart octopu spinach mussel slice foie tomato cod shrimp bass adult sauc fish food sour delic piquant crab java mac sumatra pud pea saute corn like short deep assort bread satay horseradish line arugula chorizo monkfish homemad\n",
      "even waiter n seat take said peopl apolog ask say friendli bottl terribl hour never bill refus later glass think phone though us min manag substitut somewher rude lose spoke help decid mention p suck complaint colleg complain attitud host amount behind smile parti coffe particular member worst ac much\n",
      "decor color loung nquett window chandeli spot cool tablecloth music light modern scene jazz feel intim gray wall expos bar interior spaciou ba eleg asian area dim stain fireplac rustic upstair rose deep mismatch movi gigant sleek patron mood beam print leather crowd behind accent linen charm view men upper\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  4.6675212405658546e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 190, loss=190.6867123252467, accuracy_train=0.848465266558966, accuracy_test=0.8488372093023255\n",
      "precision_train0 = 0.915662651 recall_train0 = 0.788679245 f1_score_train0 = 0.847440446\n",
      "precision_te0 = 0.919642857 recall_te0 = 0.844262295 f1_score_te0 = 0.880341880\n",
      "precision_train1 = 0.810402685 recall_train1 = 0.893617021 f1_score_train1 = 0.849978003\n",
      "precision_te1 = 0.818840580 recall_te1 = 0.911290323 f1_score_te1 = 0.862595420\n",
      "precision_train2 = 0.832323232 recall_train2 = 0.863731656 f1_score_train2 = 0.847736626\n",
      "precision_te2 = 0.808510638 recall_te2 = 0.775510204 f1_score_te2 = 0.791666667\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet stew liter sea starter zimbabw juggl z eggplant tart spinach mussel octopu slice foie tomato cod bass shrimp adult sauc sour delic fish piquant mac crab java sumatra pea saute food pud corn deep like assort short satay horseradish bread arugula line chorizo homemad monkfish\n",
      "even waiter n seat take said peopl apolog ask say friendli bottl terribl hour never bill refus later think glass phone though min us spoke somewher substitut manag lose rude help decid mention p complaint colleg suck complain attitud host amount behind smile particular parti member coffe ac worst write\n",
      "decor color loung nquett window chandeli spot cool tablecloth music modern light scene jazz intim gray wall expos feel bar interior spaciou eleg ba asian area dim stain rustic fireplac upstair rose movi deep sleek mismatch gigant patron leather beam mood crowd print linen accent behind view charm upper franchis\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  4.611222428803074e+24\n",
      "##################################################\n",
      "##################################################\n",
      "Epoch 195, loss=190.6530517578125, accuracy_train=0.8474959612277867, accuracy_test=0.8488372093023255\n",
      "precision_train0 = 0.915570175 recall_train0 = 0.787735849 f1_score_train0 = 0.846855984\n",
      "precision_te0 = 0.919642857 recall_te0 = 0.844262295 f1_score_te0 = 0.880341880\n",
      "precision_train1 = 0.801155116 recall_train1 = 0.898242368 f1_score_train1 = 0.846925425\n",
      "precision_te1 = 0.818840580 recall_te1 = 0.911290323 f1_score_te1 = 0.862595420\n",
      "precision_train2 = 0.841400618 recall_train2 = 0.856394130 f1_score_train2 = 0.848831169\n",
      "precision_te2 = 0.808510638 recall_te2 = 0.775510204 f1_score_te2 = 0.791666667\n",
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet stew liter sea starter zimbabw juggl z eggplant tart spinach mussel octopu slice foie tomato cod bass shrimp adult sauc delic sour piquant mac fish crab java saute sumatra pea corn pud deep like assort satay horseradish food bread short arugula line chorizo monkfish lentil\n",
      "even waiter n seat take said apolog peopl ask say terribl bottl friendli hour never bill refus later think phone glass min though spoke somewher substitut us lose rude manag help mention decid complaint colleg p complain suck attitud amount host smile behind ac particular parti worst member coffe write\n",
      "decor color loung nquett window chandeli spot tablecloth cool modern music light scene intim jazz gray wall expos bar interior feel spaciou eleg ba area stain asian dim rustic fireplac rose upstair movi sleek deep mismatch gigant leather patron crowd beam linen mood print accent behind view upper franchis men\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  4.5267648710040765e+24\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    loss_epoch = 0.0\n",
    "    model.train()                    # switch to training mode\n",
    "    for input_, label_ in train_dl:\n",
    "        recon, loss = model(input_, compute_loss=True)\n",
    "        # optimize\n",
    "        optimizer.zero_grad()        # clear previous gradients\n",
    "        loss.backward()              # backprop\n",
    "        optimizer.step()             # update parameters\n",
    "        # report\n",
    "        loss_epoch += loss.item()    # add loss to loss_epoch\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        # Test Model\n",
    "        pred_train = []\n",
    "        label_train = []\n",
    "        pred_test = []\n",
    "        label_test = []\n",
    "        \n",
    "        for x_train, y_train in train_dl:\n",
    "            encoded, theta_mean, theta_logvar = model.encode(x_train)\n",
    "            temp_theta_mean = theta_mean.argmax(-1).int().data.cpu().tolist()\n",
    "            temp_y_train = y_train.argmax(-1).flatten().data.cpu().tolist()\n",
    "            \n",
    "            pred_train.extend(temp_theta_mean)\n",
    "            label_train.extend(temp_y_train)\n",
    "        \n",
    "        accuracy_train, precision_train, recall_train, f1_score_train = compute_accuracy(pred_train, label_train)\n",
    "        \n",
    "        for x_test, y_test in test_dl:\n",
    "            encoded, theta_mean, theta_logvar = model.encode(x_test)\n",
    "            temp_theta_mean = theta_mean.argmax(-1).int().data.cpu().tolist()\n",
    "            temp_y_test = y_test.argmax(-1).flatten().data.cpu().tolist()\n",
    "            \n",
    "            pred_test.extend(temp_theta_mean)\n",
    "            label_test.extend(temp_y_test)\n",
    "        \n",
    "        accuracy_test, precision_test, recall_test, f1_score_test = compute_accuracy(pred_test, label_test)\n",
    "        print (\"##################################################\")\n",
    "        print('Epoch {}, loss={}, accuracy_train={}, accuracy_test={}'.format(epoch, loss_epoch / len(input_), accuracy_train, accuracy_test))\n",
    "        for k in range(num_topic):\n",
    "            print (\"precision_train{}\".format(k), \"=\" , \"{:.9f}\".format(precision_train[k]), \\\n",
    "                 \"recall_train{}\".format(k), \"=\" , \"{:.9f}\".format(recall_train[k]), \\\n",
    "                 \"f1_score_train{}\".format(k), \"=\" , \"{:.9f}\".format(f1_score_train[k]))\n",
    "            print (\"precision_te{}\".format(k), \"=\" , \"{:.9f}\".format(precision_test[k]), \\\n",
    "                 \"recall_te{}\".format(k), \"=\" , \"{:.9f}\".format(recall_test[k]), \\\n",
    "                 \"f1_score_te{}\".format(k), \"=\" , \"{:.9f}\".format(f1_score_test[k]))\n",
    "        emb = model.de_fc.weight.data.detach().cpu().numpy().T\n",
    "        print_top_words(emb, vocab, 50)\n",
    "        print_perp(model)\n",
    "        print (\"##################################################\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935 food 0 0 [9.9816942e-01 7.8819349e-04 1.0423878e-03]\n",
      "88 sauc 0 0 [9.8719537e-01 5.6452770e-04 1.2240122e-02]\n",
      "2681 chicken 0 0 [9.9999261e-01 2.2231402e-06 5.0871781e-06]\n",
      "2414 shrimp 0 0 [9.9810696e-01 1.8730439e-03 1.9972667e-05]\n",
      "1381 chees 0 0 [9.9989939e-01 1.9063911e-05 8.1581544e-05]\n",
      "1496 potato 0 0 [9.9967277e-01 2.1902409e-04 1.0821931e-04]\n",
      "105 fri 0 0 [9.9992347e-01 2.9473993e-05 4.7106540e-05]\n",
      "546 tomato 0 0 [9.9965930e-01 6.7374240e-05 2.7342312e-04]\n",
      "1347 roast 0 0 [9.9998915e-01 7.4518891e-07 1.0149953e-05]\n",
      "642 onion 0 0 [9.9939394e-01 3.2875538e-04 2.7739661e-04]\n",
      "2272 pork 0 0 [9.99999046e-01 1.08499215e-07 7.79524385e-07]\n",
      "872 goat 0 0 [9.9991977e-01 2.8738012e-05 5.1523806e-05]\n",
      "1005 grill 0 0 [9.9506575e-01 6.2269263e-04 4.3116515e-03]\n",
      "124 tuna 0 0 [1.000000e+00 4.065984e-09 3.124280e-08]\n",
      "1159 salad 0 0 [9.9990308e-01 3.8168437e-05 5.8710895e-05]\n",
      "2188 beef 0 0 [9.9995565e-01 1.2659381e-06 4.3086537e-05]\n",
      "601 tapa 0 0 [9.99554574e-01 1.12453046e-04 3.32925294e-04]\n",
      "1991 staff 1 1 [8.5364336e-06 9.9980754e-01 1.8387046e-04]\n",
      "1425 servic 1 1 [2.5133838e-07 9.9999976e-01 3.7386730e-08]\n",
      "1137 friendli 1 1 [3.7456742e-03 9.9612111e-01 1.3322175e-04]\n",
      "1009 rude 1 1 [2.9501742e-05 9.9992132e-01 4.9241626e-05]\n",
      "452 hostess 1 1 [0.00325954 0.9914061  0.00533438]\n",
      "1592 waiter 1 1 [6.1562947e-05 9.9888140e-01 1.0570809e-03]\n",
      "584 bartend 1 1 [0.00163383 0.99724895 0.00111729]\n",
      "711 waitress 1 1 [4.8685938e-04 9.9949098e-01 2.2180839e-05]\n",
      "1012 help 1 1 [4.5043053e-06 9.9789596e-01 2.0994816e-03]\n",
      "216 polit 1 1 [3.0605964e-04 9.9951136e-01 1.8249791e-04]\n",
      "1401 bar 1 1 [9.5138256e-04 9.9714077e-01 1.9078857e-03]\n",
      "1962 courteou 1 1 [8.0115302e-04 9.9889225e-01 3.0664899e-04]\n",
      "2722 member 1 1 [6.7952198e-05 9.9982482e-01 1.0730359e-04]\n",
      "368 waitstaff 1 1 [0.00203446 0.99652135 0.00144421]\n",
      "685 attitud 1 1 [5.0672506e-06 9.9977463e-01 2.2027356e-04]\n",
      "1815 reserv 1 1 [0.01920364 0.96866924 0.01212711]\n",
      "2252 tip 1 1 [4.0685291e-06 9.9986994e-01 1.2602827e-04]\n",
      "2529 atmospher 2 2 [1.7322261e-03 4.2749970e-04 9.9784029e-01]\n",
      "579 scene 2 2 [7.5249943e-08 2.6577023e-09 9.9999988e-01]\n",
      "2318 place 2 2 [4.0433966e-04 8.9053909e-05 9.9950659e-01]\n",
      "2199 tabl 2 2 [4.1779371e-05 5.3498556e-04 9.9942327e-01]\n",
      "575 outsid 2 2 [1.1319224e-06 2.2183981e-04 9.9977702e-01]\n",
      "965 area 2 2 [1.7832146e-03 9.3944527e-06 9.9820733e-01]\n",
      "463 ambianc 2 2 [1.0712124e-04 1.0272979e-03 9.9886560e-01]\n",
      "1675 outdoor 2 2 [0.00275915 0.02935636 0.9678844 ]\n",
      "1589 romant 2 2 [8.2750125e-07 2.0803639e-06 9.9999714e-01]\n",
      "2616 cozi 2 2 [2.2754537e-04 2.6751350e-04 9.9950492e-01]\n",
      "457 decor 2 2 [4.5505152e-05 7.2527223e-04 9.9922919e-01]\n",
      "1942 sit 2 2 [7.9314013e-06 9.3533090e-05 9.9989855e-01]\n",
      "2705 wall 2 2 [4.3461303e-04 4.5968132e-05 9.9951947e-01]\n",
      "2643 light 2 2 [2.2994232e-05 3.5200169e-06 9.9997354e-01]\n",
      "864 window 2 2 [1.7211127e-05 8.8819763e-07 9.9998188e-01]\n",
      "965 area 2 2 [1.7832146e-03 9.3944527e-06 9.9820733e-01]\n",
      "85 ceil 2 2 [7.3147938e-05 2.7062959e-05 9.9989974e-01]\n",
      "161 floor 2 2 [3.9893737e-07 2.4896721e-07 9.9999940e-01]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "gamma_mean, gamma_logvar = model.gamma()\n",
    "gm, gl = gamma_mean.data.cpu().numpy(), gamma_logvar.data.cpu().numpy()\n",
    "print_gamma(gm, seed_words, vocab, vocab2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Printing the Topics------------------\n",
      "babi boomer green duck sweet stew sea liter starter zimbabw juggl z eggplant tart spinach mussel octopu slice foie cod tomato bass shrimp adult delic sauc mac piquant sour saute java crab sumatra pea corn pud fish deep assort satay horseradish like bread arugula line food short chorizo monkfish lentil\n",
      "even waiter n seat take said apolog peopl ask say terribl bottl friendli hour never bill later refus think phone glass min spoke though somewher substitut lose us rude mention manag help decid complaint p colleg complain suck attitud amount host smile ac behind particular worst parti member coffe warn\n",
      "decor color loung nquett window chandeli spot tablecloth cool modern music light scene intim jazz gray expos wall interior bar spaciou eleg ba feel stain area rustic dim asian fireplac rose upstair movi sleek gigant mismatch deep leather patron beam linen crowd mood print accent behind upper view franchis antiqu\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  4.518262611250598e+24\n"
     ]
    }
   ],
   "source": [
    "emb = model.de_fc.weight.data.cpu().numpy().T\n",
    "print_top_words(emb, vocab, 50)\n",
    "print_perp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avi",
   "language": "python",
   "name": "avi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
