{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install https://download.pytorch.org/whl/cu75/torch-0.1.12.post1-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProdLDA(nn.Module):\n",
    "    def __init__(self, net_arch):\n",
    "        super(ProdLDA, self).__init__()\n",
    "        ac = net_arch\n",
    "        self.net_arch = net_arch\n",
    "        # encoder\n",
    "        self.en1_fc     = nn.Linear(ac.num_input, ac.en1_units)             # 1995 -> 100\n",
    "        self.en2_fc     = nn.Linear(ac.en1_units, ac.en2_units)             # 100  -> 100\n",
    "        self.en2_drop   = nn.Dropout(ac.drop_rate)\n",
    "        self.mean_fc    = nn.Linear(ac.en2_units, ac.num_topic)             # 100  -> 50\n",
    "        self.mean_bn    = nn.BatchNorm1d(ac.num_topic)                      # bn for mean\n",
    "        self.logvar_fc  = nn.Linear(ac.en2_units, ac.num_topic)             # 100  -> 50\n",
    "        self.logvar_bn  = nn.BatchNorm1d(ac.num_topic)                      # bn for logvar\n",
    "        # z\n",
    "        self.p_drop     = nn.Dropout(ac.drop_rate)\n",
    "        # decoder\n",
    "        self.decoder    = nn.Linear(ac.num_topic, ac.num_input)             # 50   -> 1995\n",
    "        self.decoder_bn = nn.BatchNorm1d(ac.num_input)                      # bn for decoder\n",
    "        # prior mean and variance as constant buffers\n",
    "        self.prior_mean   = torch.Tensor(1, ac.num_topic).fill_(0)\n",
    "        self.prior_var    = torch.Tensor(1, ac.num_topic).fill_(ac.variance)\n",
    "        self.prior_mean = nn.Parameter(self.prior_mean, requires_grad=False)\n",
    "        self.prior_var = nn.Parameter(self.prior_var, requires_grad=False)\n",
    "        self.prior_logvar = nn.Parameter(self.prior_var.log(), requires_grad=False)\n",
    "        # initialize decoder weight\n",
    "        if ac.init_mult != 0:\n",
    "            #std = 1. / math.sqrt( ac.init_mult * (ac.num_topic + ac.num_input))\n",
    "            self.decoder.weight.data.uniform_(0, ac.init_mult)\n",
    "        # remove BN's scale parameters\n",
    "        self.logvar_bn .weight.requires_grad = False\n",
    "        self.logvar_bn .weight.fill_(1.0)\n",
    "        self.mean_bn   .weight.requires_grad = False\n",
    "        self.mean_bn   .weight.fill_(1.0)\n",
    "        self.decoder_bn.weight.requires_grad = False\n",
    "        self.decoder_bn.weight.fill_(1.0)\n",
    "\n",
    "    def forward(self, input_, compute_loss=False, avg_loss=True):\n",
    "        # compute posterior\n",
    "        en1 = F.softplus(self.en1_fc(input_))                           # en1_fc   output\n",
    "        en2 = F.softplus(self.en2_fc(en1))                              # encoder2 output\n",
    "        en2 = self.en2_drop(en2)\n",
    "        posterior_mean   = self.mean_bn  (self.mean_fc  (en2))          # posterior mean\n",
    "        posterior_logvar = self.logvar_bn(self.logvar_fc(en2))          # posterior log variance\n",
    "        posterior_var    = posterior_logvar.exp()\n",
    "        # take sample\n",
    "        eps = input_.data.new().resize_as_(posterior_mean.data).normal_() # noise\n",
    "        z = posterior_mean + posterior_var.sqrt() * eps                 # reparameterization\n",
    "        p = F.softmax(z, dim=-1)                                                # mixture probability\n",
    "        p = self.p_drop(p)\n",
    "        # do reconstruction\n",
    "        \n",
    "        recon = F.softmax(self.decoder_bn(self.decoder(p)), dim=-1)             # reconstructed distribution over vocabulary\n",
    "\n",
    "        if compute_loss:\n",
    "            return recon, self.loss(input_, recon, posterior_mean, posterior_logvar, posterior_var, avg_loss)\n",
    "        else:\n",
    "            return recon\n",
    "\n",
    "    def loss(self, input_, recon, posterior_mean, posterior_logvar, posterior_var, avg=True):\n",
    "        # NL\n",
    "        NL  = -(input_ * (recon + 1e-10).log()).sum(1)\n",
    "        # KLD, see Section 3.3 of Akash Srivastava and Charles Sutton, 2017, \n",
    "        # https://arxiv.org/pdf/1703.01488.pdf\n",
    "        prior_mean   = self.prior_mean.expand_as(posterior_mean)\n",
    "        prior_var    = self.prior_var.expand_as(posterior_mean)\n",
    "        prior_logvar = self.prior_logvar.expand_as(posterior_mean)\n",
    "        var_division    = posterior_var  / prior_var\n",
    "        diff            = posterior_mean - prior_mean\n",
    "        diff_term       = diff * diff / prior_var\n",
    "        logvar_division = prior_logvar - posterior_logvar\n",
    "        # put KLD together\n",
    "        KLD = 0.5 * ( (var_division + diff_term + logvar_division).sum(1) - self.net_arch.num_topic )\n",
    "        # loss\n",
    "        loss = (NL + KLD)\n",
    "        # in traiming mode, return averaged loss. In testing mode, return individual loss\n",
    "        if avg:\n",
    "            return loss.mean()\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(data, min_length):\n",
    "    return np.bincount(data, minlength=min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perp(model):\n",
    "    cost=[]\n",
    "    model.eval()                        # switch to testing mode\n",
    "    input_ = tensor_te\n",
    "    recon, loss = model(input_, compute_loss=True, avg_loss=False)\n",
    "    loss = loss.data\n",
    "    counts = tensor_te.sum(1)\n",
    "    avg = (loss / counts).mean()\n",
    "    print('The approximated perplexity is: ', math.exp(avg))\n",
    "\n",
    "def visualize():\n",
    "    global recon\n",
    "    input_ = tensor_te[:10]\n",
    "    register_vis_hooks(model)\n",
    "    recon = model(input_, compute_loss=False)\n",
    "    remove_vis_hooks()\n",
    "    save_visualization('pytorch_model', 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tr = 'data/20news_clean/train.txt.npy'\n",
    "data_tr = np.load(dataset_tr, encoding=\"latin1\")\n",
    "dataset_te = 'data/20news_clean/test.txt.npy'\n",
    "data_te = np.load(dataset_te, encoding=\"latin1\")\n",
    "vocab = 'data/20news_clean/vocab.pkl'\n",
    "vocab_file = open(vocab,'rb')\n",
    "vocab = pickle.load(vocab_file)\n",
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data to one-hot representation\n",
      "Data Loaded\n",
      "Dim Training Data (11258, 1995)\n",
      "Dim Test Data (7487, 1995)\n"
     ]
    }
   ],
   "source": [
    "#--------------convert to one-hot representation------------------\n",
    "print ('Converting data to one-hot representation')\n",
    "data_tr = np.array([to_onehot(doc.astype('int'),vocab_size) for doc in data_tr if np.sum(doc)!=0])\n",
    "data_te = np.array([to_onehot(doc.astype('int'),vocab_size) for doc in data_te if np.sum(doc)!=0])\n",
    "#--------------print the data dimentions--------------------------\n",
    "print ('Data Loaded')\n",
    "print ('Dim Training Data', data_tr.shape)\n",
    "print ('Dim Test Data', data_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------make tensor datasets-------------------------------\n",
    "tensor_tr = torch.from_numpy(data_tr).float()\n",
    "tensor_te = torch.from_numpy(data_te).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    en1_units=100\n",
    "    en2_units=100\n",
    "    num_topic=50\n",
    "    num_input=1995\n",
    "    variance=0.995\n",
    "    init_mult=1.0\n",
    "    learning_rate=0.002\n",
    "    batch_size=200\n",
    "    momentum=0.99\n",
    "    num_epoch=200\n",
    "    nogpu=True\n",
    "    drop_rate=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch = args # en1_units, en2_units, num_topic, num_input\n",
    "net_arch.num_input = data_tr.shape[1]\n",
    "model = ProdLDA(net_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "# optimizer = torch.optim.SGD(model.parameters(), args.learning_rate, momentum=args.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=830.7032481411047\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5bd6cd8953c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# clear previous gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m# backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt-avitm-1.0/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pt-avitm-1.0/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.num_epoch):\n",
    "    all_indices = torch.randperm(tensor_tr.size(0)).split(args.batch_size)\n",
    "    loss_epoch = 0.0\n",
    "    model.train()                   # switch to training mode\n",
    "    for batch_indices in all_indices:\n",
    "        input_ = tensor_tr[batch_indices]\n",
    "        recon, loss = model(input_, compute_loss=True)\n",
    "        # optimize\n",
    "        optimizer.zero_grad()       # clear previous gradients\n",
    "        loss.backward()             # backprop\n",
    "        optimizer.step()            # update parameters\n",
    "        # report\n",
    "        loss_epoch += loss.item()    # add loss to loss_epoch\n",
    "    if epoch % 5 == 0:\n",
    "        print('Epoch {}, loss={}'.format(epoch, loss_epoch / len(all_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perp(model):\n",
    "    cost=[]\n",
    "    model.eval()                        # switch to testing mode\n",
    "    input_ = tensor_te\n",
    "    recon, loss = model(input_, compute_loss=True, avg_loss=False)\n",
    "    loss = loss.data\n",
    "    counts = tensor_te.sum(1)\n",
    "    avg = (loss / counts).mean()\n",
    "    print('The approximated perplexity is: ', math.exp(avg))\n",
    "\n",
    "def visualize():\n",
    "    global recon\n",
    "    input_ = tensor_te[:10]\n",
    "    register_vis_hooks(model)\n",
    "    recon = model(input_, compute_loss=False)\n",
    "    remove_vis_hooks()\n",
    "    save_visualization('pytorch_model', 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_topic_in_line(line):\n",
    "    topics = []\n",
    "    for topic, keywords in associations.items():\n",
    "        for word in keywords:\n",
    "            if word in line:\n",
    "                topics.append(topic)\n",
    "                break\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(beta, feature_names, n_top_words=10):\n",
    "    print ('---------------Printing the Topics------------------')\n",
    "    for i in range(len(beta)):\n",
    "        line = \" \".join([feature_names[j] \n",
    "                            for j in beta[i].argsort()[:-n_top_words - 1:-1]])\n",
    "        topics = identify_topic_in_line(line)\n",
    "        print('|'.join(topics))\n",
    "        print('     {}'.format(line))\n",
    "    print ('---------------End of Topics------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "associations = {\n",
    "    'jesus': ['prophet', 'jesus', 'matthew', 'christ', 'worship', 'church'],\n",
    "    'comp ': ['floppy', 'windows', 'microsoft', 'monitor', 'workstation', 'macintosh', \n",
    "              'printer', 'programmer', 'colormap', 'scsi', 'jpeg', 'compression'],\n",
    "    'car  ': ['wheel', 'tire'],\n",
    "    'polit': ['amendment', 'libert', 'regulation', 'president'],\n",
    "    'crime': ['violent', 'homicide', 'rape'],\n",
    "    'midea': ['lebanese', 'israel', 'lebanon', 'palest'],\n",
    "    'sport': ['coach', 'hitter', 'pitch'],\n",
    "    'gears': ['helmet', 'bike'],\n",
    "    'nasa ': ['orbit', 'spacecraft'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Printing the Topics------------------\n",
      "\n",
      "     apartment armenians neighbor armenian floor troops azerbaijan afraid tear town\n",
      "\n",
      "     mw pd processor eus bhj mg pl wm rg mhz\n",
      "comp \n",
      "     xt widget toolkit xlib export default implementation colormap client motif\n",
      "midea\n",
      "     lebanese crypto lebanon escrow israel nsa morality secure civilian key\n",
      "gears\n",
      "     bike rider helmet dog ride wave hall ryan seat rock\n",
      "nasa \n",
      "     shuttle processing spacecraft nasa map orbit lunar saturn solar database\n",
      "polit\n",
      "     stephanopoulos meeting president morning decision yesterday summer economy congress secretary\n",
      "comp \n",
      "     colormap expose window event visual xlib button pixel int map\n",
      "jesus\n",
      "     jesus passage verse holy prophet prophecy spirit rise matthew eternal\n",
      "comp \n",
      "     swap font nt xterm windows screen echo character printer microsoft\n",
      "\n",
      "     pp calgary detroit pt leafs philadelphia winnipeg playoff louis pittsburgh\n",
      "\n",
      "     existence observation objective absolute truth morality scientific definition experiment faith\n",
      "midea\n",
      "     jews jew israeli israel arab militia arabs peace territory land\n",
      "comp \n",
      "     scsus ide isa scsi connector ground bus jumper pin cpu\n",
      "comp \n",
      "     jumper bio connector rom floppy pin boot mb controller hd\n",
      "\n",
      "     nsa wiretap nasa japanese billion clinton crypto pgp estimate virtual\n",
      "car  \n",
      "     tire brake gear motor detector physics detect weight mile corner\n",
      "\n",
      "     food msg medicine hospital eat insurance disease patient drug health\n",
      "\n",
      "     annual app origin art gm pt st rider module cover\n",
      "\n",
      "     marriage homosexual muslims marry daughter sexual teaching islam son male\n",
      "comp \n",
      "     pixel jpeg setting image convert gif display compression windows quality\n",
      "polit\n",
      "     militia constitution regulation libertarian weapon waco batf handgun gun assault\n",
      "\n",
      "     atlanta minnesota min philadelphia york seattle los witness montreal pit\n",
      "comp \n",
      "     gateway windows driver setup microsoft mouse screen crash card menu\n",
      "comp \n",
      "     que min printer shipping pit buf det tor speaker channel\n",
      "\n",
      "     anonymous user secure usenet ripem privacy electronic mechanism server posting\n",
      "\n",
      "     db dos byte link al ah cs pop cross ax\n",
      "\n",
      "     entry cool amp cold variable voltage nuclear water circuit air\n",
      "\n",
      "     advance hus greatly appreciate thanks hello craig shape anybody brand\n",
      "comp \n",
      "     scsus ide cpu os scsi backup cache isa ibm processor\n",
      "gears\n",
      "     gear battery mouse shift bottom bike oil plug seat rear\n",
      "\n",
      "     armenian genocide armenians massacre turks armenia mountain azerbaijan escape turkey\n",
      "\n",
      "     mailing request graphics database faq pgp aspect motif favor reader\n",
      "\n",
      "     privacy volume francisco electronic ensure director policy enforcement states violate\n",
      "nasa \n",
      "     launch demand spacecraft orbit contract shuttle module rocket satellite space\n",
      "\n",
      "     atheist atheism god existence religion passage belief teaching faith religious\n",
      "\n",
      "     adapter simm motherboard quadra apple slot configuration screen connector gateway\n",
      "sport\n",
      "     team nhl coach playoff player hockey stanley leafs ice roger\n",
      "\n",
      "     saturn dealer honda amp gear engine detector transmission mile car\n",
      "\n",
      "     island mountain british secret south russian war turks nuclear greece\n",
      "\n",
      "     penalty playoff flyers puck season team score zone ice game\n",
      "\n",
      "     ripem encrypt pgp rsa des cipher toolkit implementation dec distribute\n",
      "sport\n",
      "     defensive hitter offense pitch braves score player baseball hr hit\n",
      "\n",
      "     koresh tear compound fbi cult batf waco eternal fire tank\n",
      "jesus\n",
      "     doctrine biblical pope teaching jesus revelation passage worship absolute scripture\n",
      "crime\n",
      "     handgun homicide seattle gun vancouver crime violent journal knife population\n",
      "\n",
      "     encrypt secure enforcement clipper conversation americans economic administration agency crypto\n",
      "\n",
      "     surrender ignorance gordon joke professor roger lewis associate phil georgia\n",
      "\n",
      "     hello advance greatly appreciate hus thanks anybody convert tel _eos_\n",
      "\n",
      "     printf oname output int io entry buf remark null stream\n",
      "---------------End of Topics------------------\n",
      "The approximated perplexity is:  1072.6680406237163\n"
     ]
    }
   ],
   "source": [
    "emb = model.decoder.weight.data.cpu().numpy().T\n",
    "print_top_words(emb, list(zip(*sorted(vocab.items(), key=lambda x:x[1])))[0])\n",
    "print_perp(model)\n",
    "# visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-avitm-1.0",
   "language": "python",
   "name": "pt-avitm-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
